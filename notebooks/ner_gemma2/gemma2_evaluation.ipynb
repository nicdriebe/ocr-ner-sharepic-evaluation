{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a6a475-87d1-47be-80d7-d6abe11f91f2",
   "metadata": {},
   "source": [
    "## quantitative Evaluation der Ergebnisse - Gemma 2 2B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fde4cf-172f-45cf-aac9-6add634fcd07",
   "metadata": {},
   "source": [
    "In diesem notebook wird der dem Goldstandard angepasste Output von Gemma 2 2B untersucht.\n",
    "\n",
    "Es werden Precision, Recall und F1-Score f√ºr den gesamten Datensatz berechnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39144cde-88a5-4d81-8571-4268eff26797",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b04ffb-5b95-46aa-aae7-424ebeb735d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../data/NER/gemma2/gemma2_goldstandard_adjusted.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898138c-360d-4d10-821e-dffc346d6b6d",
   "metadata": {},
   "source": [
    "#### Anzahl der Entit√§ten bei denen keine echte Entit√§tenextraktion stattgefunden hat\n",
    "Text wurde vom Modell komplett oder in gro√üen Teilen aus dem Ground Truth entnommen und zeigte keinen Zusammenhang zur gesuchten Entit√§t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb48ad2-c9a8-441a-9cd2-e967a9a694c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keine richtige Entit√§tenextraktion:\n",
      "EVENT: 21\n",
      "TOPIC: 13\n",
      "DATE: 1\n",
      "TIME: 1\n",
      "LOC: 12\n"
     ]
    }
   ],
   "source": [
    "# Entit√§ten ohne echte Textextraktion\n",
    "from collections import defaultdict # defaultdict, setzt automatisch standardwert, wenn noch keiner da ist / (int) - Intwert 0 gesetzt\n",
    "\n",
    "\n",
    "counts = defaultdict(int)\n",
    "\n",
    "for item in data:\n",
    "    for entity in item.get(\"entities\", []):\n",
    "         if entity.get(\"no_extraction\") == True:\n",
    "            label = entity.get(\"label\")\n",
    "            counts[label] += 1\n",
    "             \n",
    "\n",
    "print(\"keine richtige Entit√§tenextraktion:\")\n",
    "for label in [\"EVENT\", \"TOPIC\", \"DATE\", \"TIME\", \"LOC\"]:\n",
    "    print(f\"{label}: {counts[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff9902-18b3-4c17-958b-2ce8fdd8adde",
   "metadata": {},
   "source": [
    "#### Anzahl der Entit√§ten die inhaltich richtig vom Modell erkannt wurden, aber w√∂rtlich abwichen\n",
    "Hier sind gr√∂√üere Anpassungen eingeschlossen, wie das Anpassen von ganzen Wortgruppen und S√§tzen, vorwiegend bei \"EVENT\" und \"TOPIC\"und kleinere Anpassungen wie das Ver√§nderung von Datums- und Zeitformaten ( 2. August -> 2.8.) und das Trennen einzelner l√§ngerer \"LOC\"-Ausgaben in mehrere \"LOC\"-Entit√§ten (LOC: Hauptsr. 2, 12345 Berlin -> LOC: Hauptstr.2 und LOC: 12345 Berlin )\n",
    "\n",
    "--> siehe auch notebook [06_prepare_json_for_evaluation](06_prepare_json_for_evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4696fbe1-1e1e-4899-8be9-b785f4c0f985",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der nachtr√§glich dem Goldstandard angepasste Entit√§ten:\n",
      "EVENT: 53\n",
      "TOPIC: 46\n",
      "DATE: 15\n",
      "TIME: 35\n",
      "LOC: 100\n"
     ]
    }
   ],
   "source": [
    "# Anzahl dem Goldstandard angepasster Entit√§ten\n",
    "from collections import defaultdict # defaultdict, setzt automatisch standardwert, wenn noch keiner da ist / (int) - Intwert 0 gesetzt\n",
    "\n",
    "\n",
    "counts = defaultdict(int)\n",
    "\n",
    "for item in data:\n",
    "    for entity in item.get(\"entities\", []):\n",
    "        if entity.get(\"aligned_to_gold\") == True:\n",
    "            label = entity.get(\"label\")\n",
    "            counts[label] += 1\n",
    "\n",
    "print(\"Anzahl der nachtr√§glich dem Goldstandard angepasste Entit√§ten:\")\n",
    "for label in [\"EVENT\", \"TOPIC\", \"DATE\", \"TIME\", \"LOC\"]:\n",
    "    print(f\"{label}: {counts[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a70519-d6e0-4c4e-a0d2-2d0189f9a90b",
   "metadata": {},
   "source": [
    "---\n",
    "### Berechnung Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52345312-f0f0-40a5-8a5c-0216e63dd76f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 61826.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Gesamtbewertung ===\n",
      "Precision: 0.524\n",
      "Recall   : 0.409\n",
      "F1-Score : 0.459\n",
      "\n",
      "=== Bewertung pro Label ===\n",
      "LOC        P: 0.59  R: 0.41  F1: 0.48\n",
      "DATE       P: 0.63  R: 0.43  F1: 0.51\n",
      "TIME       P: 0.78  R: 0.69  F1: 0.73\n",
      "EVENT      P: 0.37  R: 0.36  F1: 0.36\n",
      "TOPIC      P: 0.27  R: 0.20  F1: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# === Dateien laden ===\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/gemma2_goldstandard_adjusted.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "label_names = [\"LOC\", \"DATE\", \"TIME\", \"EVENT\", \"TOPIC\"]\n",
    "\n",
    "def extract_entities_gold(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"text\", \"\").strip()\n",
    "        if label and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "def extract_entities_pred(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"standardized_text\", \"\").strip()\n",
    "        if label and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "# Mapping f√ºr schnellen Zugriff\n",
    "gemma_dict = {entry[\"file_name\"]: entry for entry in gemma_data}\n",
    "\n",
    "# Globale Auswertungsdaten\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_true_per_label = defaultdict(list)\n",
    "y_pred_per_label = defaultdict(list)\n",
    "label_stats = defaultdict(lambda: [0, 0, 0])\n",
    "all_results = []\n",
    "\n",
    "for gold_entry in tqdm(gold_data):\n",
    "    file_name = gold_entry[\"file_name\"]\n",
    "    gold_ents = extract_entities_gold(gold_entry)\n",
    "    pred_entry = gemma_dict.get(file_name)\n",
    "    pred_ents = extract_entities_pred(pred_entry) if pred_entry else {}\n",
    "\n",
    "    true_pos, false_pos, false_neg = [], [], []\n",
    "\n",
    "    for label in label_names:\n",
    "        gold_texts = set(t.strip() for t in gold_ents.get(label, []) if isinstance(t, str))\n",
    "        pred_texts = set(t.strip() for t in pred_ents.get(label, []) if isinstance(t, str))\n",
    "\n",
    "        # True Positives\n",
    "        matched = gold_texts & pred_texts\n",
    "        for text in matched:\n",
    "            y_true_all.append(1)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(1)\n",
    "            y_pred_per_label[label].append(1)\n",
    "            true_pos.append({\"label\": label, \"text\": text})\n",
    "\n",
    "        # False Negatives\n",
    "        for text in gold_texts - matched:\n",
    "            y_true_all.append(1)\n",
    "            y_pred_all.append(0)\n",
    "            y_true_per_label[label].append(1)\n",
    "            y_pred_per_label[label].append(0)\n",
    "            false_neg.append({\"label\": label, \"text\": text})\n",
    "\n",
    "        # False Positives\n",
    "        for text in pred_texts - matched:\n",
    "            y_true_all.append(0)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(0)\n",
    "            y_pred_per_label[label].append(1)\n",
    "            false_pos.append({\"label\": label, \"text\": text})\n",
    "\n",
    "        # Pro-Label Z√§hlung\n",
    "        label_stats[label][0] += len(matched)\n",
    "        label_stats[label][1] += len(pred_texts - matched)\n",
    "        label_stats[label][2] += len(gold_texts - matched)\n",
    "\n",
    "    # Metriken pro Datei\n",
    "    tp_count = len(true_pos)\n",
    "    fp_count = len(false_pos)\n",
    "    fn_count = len(false_neg)\n",
    "\n",
    "    precision_local = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0\n",
    "    recall_local = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0\n",
    "    f1_local = 2 * precision_local * recall_local / (precision_local + recall_local) if (precision_local + recall_local) > 0 else 0\n",
    "\n",
    "    result_entry = {\n",
    "        \"file_name\": file_name,\n",
    "        \"precision\": precision_local,\n",
    "        \"recall\": recall_local,\n",
    "        \"f1\": f1_local,\n",
    "        \"true_positives\": true_pos,\n",
    "        \"false_positives\": false_pos,\n",
    "        \"false_negatives\": false_neg\n",
    "    }\n",
    "    all_results.append(result_entry)\n",
    "\n",
    "# Speichern\n",
    "with open(\"../../data/NER/gemma2/results_gemma.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# === Gesamtmetriken ===\n",
    "precision = sum(y_pred_all[i] == y_true_all[i] == 1 for i in range(len(y_true_all))) / sum(y_pred_all) if sum(y_pred_all) > 0 else 0\n",
    "recall = sum(y_pred_all[i] == y_true_all[i] == 1 for i in range(len(y_true_all))) / sum(y_true_all) if sum(y_true_all) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\n=== Gesamtbewertung ===\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1-Score : {f1:.3f}\")\n",
    "\n",
    "# === Bewertung pro Label ===\n",
    "print(\"\\n=== Bewertung pro Label ===\")\n",
    "for label, (tp_l, fp_l, fn_l) in label_stats.items():\n",
    "    p = tp_l / (tp_l + fp_l) if (tp_l + fp_l) > 0 else 0\n",
    "    r = tp_l / (tp_l + fn_l) if (tp_l + fn_l) > 0 else 0\n",
    "    f = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "    print(f\"{label:<10} P: {p:.2f}  R: {r:.2f}  F1: {f:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae353e22-690e-44f6-b49d-7ea3ce90bdac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATE': {'matches': 124, 'total': 282},\n",
       " 'LOC': {'matches': 165, 'total': 391},\n",
       " 'TIME': {'matches': 151, 'total': 210},\n",
       " 'EVENT': {'matches': 84, 'total': 227},\n",
       " 'TOPIC': {'matches': 55, 'total': 259}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2_goldstandard_adjusted.json\", encoding=\"utf-8\") as f:\n",
    "    ner = json.load(f)\n",
    "\n",
    "# Erzeuge Lookup nach file_name f√ºr schnellen Zugriff\n",
    "gold_by_file = {entry[\"file_name\"]: entry for entry in gold}\n",
    "ner_by_file = {entry[\"file_name\"]: entry for entry in ner}\n",
    "\n",
    "# Z√§hler f√ºr genaue √úbereinstimmungen pro Label\n",
    "match_counts = defaultdict(int)\n",
    "total_counts = defaultdict(int)\n",
    "\n",
    "def get_entities_gold(entry):\n",
    "    \"\"\"Erzeuge ein Dict {label: set of texts} f√ºr eine Datei\"\"\"\n",
    "    entities = defaultdict(set)\n",
    "    for e in entry.get(\"entities\", []):\n",
    "        label = e[\"label\"]\n",
    "        text = e[\"text\"].strip().lower()\n",
    "        entities[label].add(text)\n",
    "    return entities\n",
    "\n",
    "def get_entities_pred(entry):\n",
    "    \"\"\"Erzeuge ein Dict {label: set of texts} f√ºr eine Datei\"\"\"\n",
    "    entities = defaultdict(set)\n",
    "    for e in entry.get(\"entities\", []):\n",
    "        label = e[\"label\"]\n",
    "        text = e[\"standardized_text\"].strip().lower()\n",
    "        entities[label].add(text)\n",
    "    return entities\n",
    "\n",
    "# Iteriere √ºber alle Dateien im Goldstandard\n",
    "for file_name, gold_entry in gold_by_file.items():\n",
    "    ner_entry = ner_by_file.get(file_name)\n",
    "    if ner_entry is None:\n",
    "        continue  # Kein Output vorhanden f√ºr diese Datei\n",
    "\n",
    "    gold_entities = get_entities_gold(gold_entry)\n",
    "    ner_entities = get_entities_pred(ner_entry)\n",
    "\n",
    "    # Betrachte alle Labels, die vorkommen\n",
    "    all_labels = set(gold_entities.keys()) | set(ner_entities.keys())\n",
    "    for label in all_labels:\n",
    "        gold_set = gold_entities.get(label, set())\n",
    "        ner_set = ner_entities.get(label, set())\n",
    "\n",
    "        # Z√§hle Totalf√§lle (Gold)\n",
    "        total_counts[label] += len(gold_set)\n",
    "\n",
    "        # Z√§hle nur exakte √úbereinstimmungen\n",
    "        matches = gold_set & ner_set\n",
    "        match_counts[label] += len(matches)\n",
    "\n",
    "# Ergebnis als dict\n",
    "results = {label: {\"matches\": match_counts[label], \"total\": total_counts[label]} for label in total_counts}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f36ee-322b-4685-ab74-441dee9a10d9",
   "metadata": {},
   "source": [
    "---\n",
    "#### Berechnung ohne Einbeziehung von TOPIC f√ºr den sp√§teren Vergleich mit Modellkombination Flair + regelbasierte Erkennung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df105903-a5ba-4906-af16-c82c891c09cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 66397.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Gesamtergebnis\n",
      "Precision: 0.582\n",
      "Recall:    0.455\n",
      "F1-Score:  0.511\n",
      "\n",
      "üìä Metriken pro Kategorie:\n",
      "Label  Precision  Recall  F1-Score  Anzahl in Gold  Anzahl Predicted\n",
      " DATE      0.626   0.428     0.508             290               198\n",
      "EVENT      0.368   0.357     0.363             235               228\n",
      "  LOC      0.589   0.407     0.482             405               280\n",
      " TIME      0.783   0.692     0.734             214               189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# === Dateien laden ===\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/gemma2_goldstandard_adjusted.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "# === Relevante Labels (ohne TOPIC) ===\n",
    "label_names = [\"LOC\", \"DATE\", \"TIME\", \"EVENT\"]\n",
    "\n",
    "# === Entit√§ten extrahieren ===\n",
    "def extract_entities_gold(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"text\", \"\").strip()\n",
    "        if label in label_names and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "def extract_entities_pred(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"standardized_text\", \"\").strip()\n",
    "        if label in label_names and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "# === Mapping der Vorhersagen f√ºr schnellen Zugriff ===\n",
    "gemma_dict = {entry[\"file_name\"]: entry for entry in gemma_data}\n",
    "\n",
    "# === Vergleich vorbereiten ===\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_true_per_label = defaultdict(list)\n",
    "y_pred_per_label = defaultdict(list)\n",
    "label_stats = defaultdict(lambda: [0, 0, 0])\n",
    "all_results = []\n",
    "\n",
    "# === Vergleichsloop √ºber alle Goldstandard-Dateien ===\n",
    "for gold_entry in tqdm(gold_data):\n",
    "    file_name = gold_entry[\"file_name\"]\n",
    "    gold_ents = extract_entities_gold(gold_entry)\n",
    "    pred_entry = gemma_dict.get(file_name)\n",
    "    pred_ents = extract_entities_pred(pred_entry) if pred_entry else {}\n",
    "\n",
    "    true_pos, false_pos, false_neg = [], [], []\n",
    "\n",
    "    for label in label_names:\n",
    "        gold_texts = set(t.strip() for t in gold_ents.get(label, []) if isinstance(t, str))\n",
    "        pred_texts = set(t.strip() for t in pred_ents.get(label, []) if isinstance(t, str))\n",
    "\n",
    "        # True Positives\n",
    "        matched = gold_texts & pred_texts\n",
    "        for text in matched:\n",
    "            y_true_all.append(1)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(1)\n",
    "            y_pred_per_label[label].append(1)\n",
    "            true_pos.append({\"label\": label, \"text\": text})\n",
    "\n",
    "        # False Negatives\n",
    "        for text in gold_texts - matched:\n",
    "            y_true_all.append(1)\n",
    "            y_pred_all.append(0)\n",
    "            y_true_per_label[label].append(1)\n",
    "            y_pred_per_label[label].append(0)\n",
    "            false_neg.append({\"label\": label, \"text\": text})\n",
    "\n",
    "        # False Positives\n",
    "        for text in pred_texts - matched:\n",
    "            y_true_all.append(0)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(0)\n",
    "            y_pred_per_label[label].append(1)\n",
    "            false_pos.append({\"label\": label, \"text\": text})\n",
    "\n",
    "        # Labelweise Statistiken\n",
    "        label_stats[label][0] += len(matched)\n",
    "        label_stats[label][1] += len(pred_texts - matched)\n",
    "        label_stats[label][2] += len(gold_texts - matched)\n",
    "\n",
    "    # Lokale Metriken berechnen\n",
    "    tp = len(true_pos)\n",
    "    fp = len(false_pos)\n",
    "    fn = len(false_neg)\n",
    "\n",
    "    precision_local = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall_local = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_local = 2 * precision_local * recall_local / (precision_local + recall_local) if (precision_local + recall_local) > 0 else 0\n",
    "\n",
    "    all_results.append({\n",
    "        \"file_name\": file_name,\n",
    "        \"precision\": precision_local,\n",
    "        \"recall\": recall_local,\n",
    "        \"f1\": f1_local,\n",
    "        \"true_positives\": true_pos,\n",
    "        \"false_positives\": false_pos,\n",
    "        \"false_negatives\": false_neg\n",
    "    })\n",
    "\n",
    "# === Ergebnisse speichern ===\n",
    "with open(\"../../data/NER/gemma2/results_gemma_without_topic.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# === Gesamtmetriken ===\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_all, y_pred_all, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Gesamtergebnis\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "\n",
    "# === Pro-Label-Metriken ===\n",
    "rows = []\n",
    "for label in label_names:\n",
    "    y_true = y_true_per_label[label]\n",
    "    y_pred = y_pred_per_label[label]\n",
    "\n",
    "    if not y_true and not y_pred:\n",
    "        p = r = f = 0.0\n",
    "    else:\n",
    "        p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "\n",
    "    rows.append({\n",
    "        \"Label\": label,\n",
    "        \"Precision\": round(p, 3),\n",
    "        \"Recall\": round(r, 3),\n",
    "        \"F1-Score\": round(f, 3),\n",
    "        \"Anzahl in Gold\": sum(y_true),\n",
    "        \"Anzahl Predicted\": sum(y_pred)\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows).sort_values(\"Label\")\n",
    "print(\"\\nüìä Metriken pro Kategorie:\")\n",
    "print(df_metrics.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7448b5b-2d64-4e21-9b5c-7704e5a25ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
