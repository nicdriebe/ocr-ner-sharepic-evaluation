{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae027cd-6a3e-48d5-a4d8-666b73ee0f45",
   "metadata": {},
   "source": [
    "# Gemma 2 Evaluation - 03 -\n",
    "\n",
    "In diesem notebook wird untersucht wie gut Gemma 2 die gewünschten Entitäten (EVENT, TOPIC, DATE, TIME, LOC) erkennt.\n",
    "\n",
    "Es wird folgendes Model genutzt: **\"gemma-2-2b-it\"**   \n",
    "kleinstes Modell der Gemma2 Modelle  \n",
    "(2B model was trained with 2 trillion tokens)\n",
    "\n",
    "Die Performance von Gemma 2 wird auf dem Ground Truth untersucht.\n",
    "\n",
    "**erste Quantitative Analyse - Berechnung von Precision, Recall und F1-Score - nur als erster Vergleich zw den unterschiedlichen Prompts**\n",
    "\n",
    "\n",
    "\n",
    "Bei den ersten Ausgaben (siehe [notebook 01_gemma2_prompt_test1](01_gemma2_prompt_test1.ipynb) und [notebook 02_gemma2_prompt_test2](02_gemma2_prompt_test2.ipynb)) zeigte sich , dass nicht für jeden Text Entitäten extrahiert wurden.   \n",
    "Es wurden Fehler angezeigt, die die Ausgabe als Json betreffen. Zudem halluzinoerte das Modell, bzw nutze die Beispiel im Prompt um Entitäten zu annotieren.  \n",
    "Der Output wird nun nicht im Jsonformat gespeichert, sondern als String in einer csv Datei.    \n",
    "Der Prompt wird dementsprechend etwas modifiziert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834393b8-90c2-4e21-8e76-46db53f072da",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Prompt:**\n",
    "\n",
    "prompt = f\"\"\"\n",
    "            Der folgende Text stammt von einem Veranstaltungsplakat. Extrahiere, wenn möglich, die folgenden Informationen:\n",
    "\n",
    "            - **Ort** (z. B. Straßen mit Hausnummern, Plätze, Gebäude, Stadtteile, Städte)\n",
    "            - **Datum** (z. B. \"21.12.\", \"Dienstag\", \"9. November\", \"8.8.2021\")\n",
    "            - **Zeit** (z. B. \"19 Uhr\", \"18:00 Uhr\")\n",
    "            - **Veranstaltungsart** (z. B. \"Kundgebung\", \"Demonstration\", \"Feier\")\n",
    "            - **Thema**\n",
    "\n",
    "            Regeln:\n",
    "            - Gib nur Informationen an, bei denen du dir sicher bist.\n",
    "            - Verwende **ausschließlich Wörter aus dem Originaltext**.\n",
    "            - Nicht alle Felder müssen vorhanden sein.\n",
    "            - Mehrfache Einträge pro Feld sind möglich.\n",
    "\n",
    "            Gib das Ergebnis exakt im folgenden Format zurück:\n",
    "\n",
    "            Entitäten: Ort(...), Datum(...), Zeit(...), Kategorie(...), Thema(...)\n",
    "\n",
    "            Hier ist der Text:\n",
    "            {text}\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903830f3-ef5e-4705-8d50-977a2d7301e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5597846-0f80-4165-8c92-e0dacecd8b5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4748e153-8361-45b9-adbc-7d8bf206c092",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ce9bf2aba04ba9b58dfd7807e9ae6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcdf7d7c-97da-4c4d-b266-448fee48c2bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/blongsch/ikt/lib/python3.11/site-packages (4.53.2)\n",
      "Requirement already satisfied: torch in /Users/blongsch/ikt/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: accelerate in /Users/blongsch/ikt/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/blongsch/ikt/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/blongsch/ikt/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: sympy in /Users/blongsch/ikt/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/blongsch/ikt/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/blongsch/ikt/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: psutil in /Users/blongsch/ikt/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd45a198-18c7-4c66-8ff2-52669c720d19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a976f6c73a5492d8e0a028edc8249e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cpu\") #habe kein gpu, deshab cpu\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f985c4-93ef-4f37-933e-c11cb9e95c34",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ff503-5752-4ddb-b07a-d6530af0add6",
   "metadata": {},
   "source": [
    "### Auf Datensatz iterieren und Output im CSV-Format speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b232fb-d540-427c-b979-cea83f308f1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b46eee5fc44255a0f8f494611e3e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Funktion extract_entities\n",
    "import csv\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Model und Pipeline\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=-1)\n",
    "\n",
    "def extract_entities(data_path, output):\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    with open(output, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"file_name\", \"output\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for eintrag in data:\n",
    "            file_name = eintrag[\"file_name\"]\n",
    "            text = eintrag[\"text\"]\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            Der folgende Text stammt von einem Veranstaltungsplakat. Extrahiere, wenn möglich, die folgenden Informationen:\n",
    "\n",
    "            - **Ort** (z. B. Straßen mit Hausnummern, Plätze, Gebäude, Stadtteile, Städte)\n",
    "            - **Datum** (z. B. \"21.12.\", \"Dienstag\", \"9. November\", \"8.8.2021\")\n",
    "            - **Zeit** (z. B. \"19 Uhr\", \"18:00 Uhr\")\n",
    "            - **Veranstaltungsart** (z. B. \"Kundgebung\", \"Demonstration\", \"Feier\")\n",
    "            - **Thema**\n",
    "\n",
    "            Regeln:\n",
    "            - Gib nur Informationen an, bei denen du dir sicher bist.\n",
    "            - Verwende **ausschließlich Wörter aus dem Originaltext**.\n",
    "            - Nicht alle Felder müssen vorhanden sein.\n",
    "            - Mehrfache Einträge pro Feld sind möglich.\n",
    "\n",
    "            Gib das Ergebnis exakt im folgenden Format zurück:\n",
    "\n",
    "            Entitäten: Ort(...), Datum(...), Zeit(...), Kategorie(...), Thema(...)\n",
    "\n",
    "            Hier ist der Text:\n",
    "            {text}\n",
    "            \"\"\"\n",
    "\n",
    "            try:\n",
    "                output = generator(prompt, max_new_tokens=400)[0][\"generated_text\"]\n",
    "                writer.writerow({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"output\": output.strip()\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler bei {file_name}: {e}\")\n",
    "                writer.writerow({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"output\": f\"Fehler: {str(e)}\"\n",
    "                })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c3154b-f41f-4aac-a369-9e45d79f29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = \"../../data/data_annotated.json\"\n",
    "output = \"../../data/NER/gemma2/prompt3/gemma2_entity_output_prompt3_1.csv\"\n",
    "\n",
    "extract_entities(data, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ff13d2-38b0-49cb-acfa-dd141c201697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.jpg</td>\n",
       "      <td>Der folgende Text stammt von einem Veranstaltu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.jpg</td>\n",
       "      <td>Der folgende Text stammt von einem Veranstaltu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.jpg</td>\n",
       "      <td>Der folgende Text stammt von einem Veranstaltu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>Der folgende Text stammt von einem Veranstaltu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>Der folgende Text stammt von einem Veranstaltu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                                             output\n",
       "0  0001.jpg  Der folgende Text stammt von einem Veranstaltu...\n",
       "1  0002.jpg  Der folgende Text stammt von einem Veranstaltu...\n",
       "2  0003.jpg  Der folgende Text stammt von einem Veranstaltu...\n",
       "3  0004.jpg  Der folgende Text stammt von einem Veranstaltu...\n",
       "4  0006.jpg  Der folgende Text stammt von einem Veranstaltu..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/NER/gemma2/prompt3/gemma2_entity_output_prompt3_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234991d8-3a7a-412b-9306-f186f9e952b9",
   "metadata": {},
   "source": [
    "### CSV-Datei bereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a44492-bbf0-436c-b0d9-f8327f641c06",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Prompt in Ausgabetext entfernen\n",
    "import csv\n",
    "\n",
    "PROMPT_START = \"Der folgende Text stammt von einem Veranstaltungsplakat.\"\n",
    "TEXT_MARKER = \"Hier ist der Text:\"\n",
    "\n",
    "def clean_csv(input_path, output_path):\n",
    "    with open(input_path, newline='', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        \n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            original_output = row[\"output\"]\n",
    "            if PROMPT_START in original_output and TEXT_MARKER in original_output:\n",
    "                # alles nach \"Hier ist der Text:\" behalten\n",
    "                cleaned = original_output.split(TEXT_MARKER, 1)[-1].strip()\n",
    "                row[\"output\"] = cleaned\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f242a7-1c5f-479c-a8b3-bf0031796a57",
   "metadata": {},
   "source": [
    "zusätzliches manuelles bearbeiten direkt in der Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd4e3a-33db-4434-a650-98dfcab00cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv(\"../../data/NER/gemma2/prompt3/gemma2_entity_output_prompt3_1.csv\", \"../../data/NER/gemma2/prompt3/gemma2_entity_output_prompt3_1_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f24f527-d29c-4438-8555-ae3f3bb6c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.jpg</td>\n",
       "      <td>Entitäten: Ort (Großer Garten), Datum (8.8.202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.jpg</td>\n",
       "      <td>Entitäten: Ort: Mahnmal Levetzowstraße, Berlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>**Ort:** Grundschule Islandstraße, Islandstraß...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>Entitäten: Ort (Gestohlene Straße), Datum (21....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                                             output\n",
       "0  0001.jpg                                                NaN\n",
       "1  0002.jpg  Entitäten: Ort (Großer Garten), Datum (8.8.202...\n",
       "2  0003.jpg  Entitäten: Ort: Mahnmal Levetzowstraße, Berlin...\n",
       "3  0004.jpg  **Ort:** Grundschule Islandstraße, Islandstraß...\n",
       "4  0006.jpg  Entitäten: Ort (Gestohlene Straße), Datum (21...."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_clean = pd.read_csv(\"../../data/NER/gemma2/prompt3/gemma2_entity_output_prompt3_1_cleaned.csv\", na_values=[\"\"])\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fcb7482-52c1-4c8e-aa29-c64e0e3074b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl Dateien: 200\n",
      "Ungültige Einträge (keine Entities): 24\n",
      "Gültige Einträge (Entities vorhanden): 176\n"
     ]
    }
   ],
   "source": [
    "# auf \"leere\"/ ungültige Einträge prüfen\n",
    "gesamt = len(df_clean)\n",
    "no_entities = df_clean[\"output\"].isna().sum()\n",
    "entities = df_clean[\"output\"].notna().sum()\n",
    "\n",
    "print(f\"Gesamtanzahl Dateien: {gesamt}\")\n",
    "print(f\"Ungültige Einträge (keine Entities): {no_entities}\")\n",
    "print(f\"Gültige Einträge (Entities vorhanden): {entities}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b903478a-8d71-4e29-a486-6eccb3663c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gewünschtes Format eingehalten: 18\n"
     ]
    }
   ],
   "source": [
    "format_ok = df_clean[df_clean[\"output\"].str.startswith(\"Entitäten:\", na=False)]\n",
    "anzahl = len(format_ok)\n",
    "print(\"gewünschtes Format eingehalten:\", anzahl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68e50969-2d45-410f-a88c-884539b97249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "datum = df_clean[\"output\"].str.contains(\"21.12\", na=False) \n",
    "anzahl = datum.sum()\n",
    "print(anzahl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99ac9566-50a1-44b0-b1d3-1b29c0a0a0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "thema = df[\"output\"].str.contains(\"Kundgebung\", na=False)\n",
    "anzahl = thema.sum()\n",
    "print(anzahl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b61291-ab6e-4748-b73f-5b1510dd2b25",
   "metadata": {},
   "source": [
    "---> bei 200 Einträgen wurde jedes mal \"Kundgebung\" als Veranstaltungsart angegeben. Das Modell hat sich sehr an den Beispielen, die im Prompt angegeben waren orientiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7a095-f72d-4e17-967c-6e3a89755058",
   "metadata": {},
   "source": [
    "**---> Der Output wird nicht weiter im notebook analysiert**  \n",
    "Bei Durchsicht des Dokuments ergab sich, dass das Modell überproportional häufig Beispiele des Prompts für die eigene Ausgabe verwendet hat. \n",
    "Durch das nicht einheitliche Ausgabeformat ist eine systematische Analyse im notebook zu aufwändig und wird deshalb verworfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83dab1-05f2-467e-94b8-58a2dd9de0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ccfa0-108e-4f07-81b0-47777cc52b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
