{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae027cd-6a3e-48d5-a4d8-666b73ee0f45",
   "metadata": {},
   "source": [
    "# Gemma 2 Evaluation - 02 -\n",
    "\n",
    "In diesem notebook wird untersucht wie gut Gemma 2 die gew√ºnschten Entit√§ten (EVENT, TOPIC, DATE, TIME, LOC) erkennt.\n",
    "\n",
    "Es wird folgendes Model genutzt: **\"gemma-2-2b-it\"**   \n",
    "kleinstes Modell der Gemma2 Modelle  \n",
    "(2B model was trained with 2 trillion tokens)\n",
    "\n",
    "Die Performance von Gemma 2 wird auf dem Ground Truth untersucht.\n",
    "\n",
    "**erste Quantitative Analyse - Berechnung von Precision, Recall und F1-Score - nur als erster Vergleich zw den unterschiedlichen Prompts**\n",
    "\n",
    "--> zwei Durchl√§ufe\n",
    "\n",
    "\n",
    "--> Bei den ersten Ausgaben ([siehe notebook 01_gemma2_prompt_test1](01_gemma2_prompt_test1.ipynb)) zeigte sich , dass nicht f√ºr jeden Text Entit√§ten extrahiert wurden.   \n",
    "Es wurden Fehler angezeigt, die die Ausgabe als Json betreffen. Zudem wurden W√∂rter \"erfunden\", die nicht im Text vorkommen. Das Modell halluzinierte also.   \n",
    "Der Prompt wird dementsprechend etwas modifiziert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834393b8-90c2-4e21-8e76-46db53f072da",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Prompt:**\n",
    "\n",
    "prompt = f\"\"\"\n",
    "        Der folgende Text stammt von einem Veranstaltungsplakat. Extrahiere, wenn m√∂glich, die folgenden Informationen:\n",
    "        \n",
    "        - **Ort** (z.‚ÄØB. Stra√üen mit Hausnummern, Pl√§tze, Geb√§ude, Stadtteile, St√§dte)\n",
    "        - **Datum** (z.‚ÄØB. \"21.12.\", \"Dienstag\", \"9. November\", \"8.8.2021\")\n",
    "        - **Zeit** (z.‚ÄØB. \"19 Uhr\", \"18:00 Uhr\")\n",
    "        - **Veranstaltungsart** (z.‚ÄØB. \"Kundgebung\", \"Demonstration\", \"Feier\")\n",
    "        - **Thema** (z.‚ÄØB. \"Solidarit√§t mit...\", \"Gedenken an...\", \"f√ºr Frieden\")\n",
    "        \n",
    "        Regeln:\n",
    "        - Gib nur Informationen an, bei denen du dir sicher bist.\n",
    "        - Verwende **ausschlie√ülich W√∂rter aus dem Originaltext**.\n",
    "        - Nicht alle Felder m√ºssen vorhanden sein.\n",
    "        - Mehrfache Eintr√§ge pro Feld sind m√∂glich.\n",
    "        \n",
    "        Gib das Ergebnis exakt im folgenden Format zur√ºck:\n",
    "        \n",
    "        ```json\n",
    "        {{\n",
    "          \"Ort\": [...],\n",
    "          \"Datum\": [...],\n",
    "          \"Zeit\": [...],\n",
    "          \"Kategorie\": [...],\n",
    "          \"Thema\": [...]\n",
    "        }}\n",
    "\n",
    "        \n",
    "        Hier ist der Text:\n",
    "        {text}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903830f3-ef5e-4705-8d50-977a2d7301e0",
   "metadata": {},
   "source": [
    "**---> es wurden zwei Durchl√§ufe mit demselben Prompt gemacht**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5597846-0f80-4165-8c92-e0dacecd8b5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4748e153-8361-45b9-adbc-7d8bf206c092",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ce9bf2aba04ba9b58dfd7807e9ae6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcdf7d7c-97da-4c4d-b266-448fee48c2bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/blongsch/ikt/lib/python3.11/site-packages (4.53.2)\n",
      "Requirement already satisfied: torch in /Users/blongsch/ikt/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: accelerate in /Users/blongsch/ikt/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/blongsch/ikt/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/blongsch/ikt/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/blongsch/ikt/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: sympy in /Users/blongsch/ikt/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/blongsch/ikt/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/blongsch/ikt/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: psutil in /Users/blongsch/ikt/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blongsch/ikt/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/blongsch/ikt/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd45a198-18c7-4c66-8ff2-52669c720d19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aabcb029f29419496bd648b42e8a4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cpu\") #habe kein gpu, deshab cpu\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f985c4-93ef-4f37-933e-c11cb9e95c34",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ff503-5752-4ddb-b07a-d6530af0add6",
   "metadata": {},
   "source": [
    "### Auf Datensatz iterieren und Output im Json-Format speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b232fb-d540-427c-b979-cea83f308f1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5903d6e5456f4b179eb9923481d47462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Funktion extract_entities\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "\n",
    "# Model und Pipeline\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=-1)\n",
    "\n",
    "def extract_entities(data):\n",
    "    results = []\n",
    "\n",
    "    for eintrag in data:\n",
    "        file_name = eintrag[\"file_name\"]\n",
    "        text = eintrag[\"text\"]\n",
    "    \n",
    "        prompt = f\"\"\"\n",
    "        Der folgende Text stammt von einem Veranstaltungsplakat. Extrahiere, wenn m√∂glich, die folgenden Informationen:\n",
    "        \n",
    "        - **Ort** (z.‚ÄØB. Stra√üen mit Hausnummern, Pl√§tze, Geb√§ude, Stadtteile, St√§dte)\n",
    "        - **Datum** (z.‚ÄØB. \"21.12.\", \"Dienstag\", \"9. November\", \"8.8.2021\")\n",
    "        - **Zeit** (z.‚ÄØB. \"19 Uhr\", \"18:00 Uhr\")\n",
    "        - **Veranstaltungsart** (z.‚ÄØB. \"Kundgebung\", \"Demonstration\", \"Feier\")\n",
    "        - **Thema** (z.‚ÄØB. \"Solidarit√§t mit...\", \"Gedenken an...\", \"f√ºr Frieden\")\n",
    "        \n",
    "        Regeln:\n",
    "        - Gib nur Informationen an, bei denen du dir sicher bist.\n",
    "        - Verwende **ausschlie√ülich W√∂rter aus dem Originaltext**.\n",
    "        - Nicht alle Felder m√ºssen vorhanden sein.\n",
    "        - Mehrfache Eintr√§ge pro Feld sind m√∂glich.\n",
    "        \n",
    "        Gib das Ergebnis exakt im folgenden Format zur√ºck:\n",
    "        \n",
    "        ```json\n",
    "        {{\n",
    "          \"Ort\": [...],\n",
    "          \"Datum\": [...],\n",
    "          \"Zeit\": [...],\n",
    "          \"Kategorie\": [...],\n",
    "          \"Thema\": [...]\n",
    "        }}\n",
    "\n",
    "        \n",
    "        Hier ist der Text:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            output = generator(prompt, max_new_tokens=400)[0][\"generated_text\"]\n",
    "            extracted_json = output.split(\"```json\")[-1].split(\"```\")[0].strip()  # nur Output nach \"```json\" wird genommen\n",
    "            extracted = json.loads(extracted_json)\n",
    "        \n",
    "            results.append({\n",
    "                \"file_name\": file_name,\n",
    "                \"entities\": extracted\n",
    "            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {file_name}: {e}\")\n",
    "            results.append({\n",
    "                \"file_name\": file_name,\n",
    "                \"entities\": None,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c3154b-f41f-4aac-a369-9e45d79f29c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler bei 0015.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0023.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0027.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0039.jpeg: Expecting ',' delimiter: line 7 column 1 (char 137)\n",
      "Fehler bei 0057.jpg: Invalid control character at: line 2 column 321 (char 322)\n",
      "Fehler bei 0064.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0080.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0089.jpeg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0091.jpg: Expecting ',' delimiter: line 7 column 1 (char 160)\n",
      "Fehler bei 0093.jpg: Expecting ',' delimiter: line 5 column 394 (char 546)\n",
      "Fehler bei 0100.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0101.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0116.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0122.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0134.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0151.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0152.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0170.jpeg: Expecting ',' delimiter: line 7 column 1 (char 168)\n",
      "Fehler bei 0173.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0183.jpg: Expecting ',' delimiter: line 3 column 3 (char 110)\n",
      "Fehler bei 0186.jpg: Expecting ',' delimiter: line 7 column 1 (char 173)\n",
      "Fehler bei 0204.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0205.jpg: Expecting ',' delimiter: line 7 column 1 (char 145)\n",
      "Fehler bei 0212.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0213.jpg: Expecting value: line 4 column 24 (char 82)\n",
      "Fehler bei 0226.jpg: Expecting value: line 2 column 19 (char 20)\n",
      "Fehler bei 0240.jpg: Expecting value: line 5 column 30 (char 122)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "#sys.path.append(os.path.abspath(\"..\"))\n",
    "#from ressourcen_monitor import monitor\n",
    "\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "#@monitor(full_name=\"Gemma2 Prompt1_2 NER\")\n",
    "#def run_ner():\n",
    "#    return extract_entities(data)\n",
    "#results = run_ner()\n",
    "\n",
    "results = extract_entities(data)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234991d8-3a7a-412b-9306-f186f9e952b9",
   "metadata": {},
   "source": [
    "### Json-Datei bereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bb9554-1d0a-4c90-9940-d77456d6d946",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl Dateien: 200\n",
      "Ung√ºltige Eintr√§ge (keine Entities oder kaputt): 27\n",
      "  ‚îî‚îÄ‚îÄ davon mit 'error'-Feld: 27\n",
      "G√ºltige Eintr√§ge (Entities vorhanden): 173\n"
     ]
    }
   ],
   "source": [
    "# auf \"leere\"/ ung√ºltige Eintr√§ge pr√ºfen\n",
    "import json\n",
    "\n",
    "# JSON laden\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Z√§hler initialisieren\n",
    "gesamt = len(data)\n",
    "ungueltig = 0\n",
    "mit_error = 0\n",
    "gueltig = 0\n",
    "\n",
    "for eintrag in data:\n",
    "    entities = eintrag.get(\"entities\")\n",
    "    \n",
    "    if not entities or not isinstance(entities, dict):\n",
    "        ungueltig += 1\n",
    "        if \"error\" in eintrag:\n",
    "            mit_error += 1\n",
    "    else:\n",
    "        gueltig += 1\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"Gesamtanzahl Dateien: {gesamt}\")\n",
    "print(f\"Ung√ºltige Eintr√§ge (keine Entities oder kaputt): {ungueltig}\")\n",
    "print(f\"  ‚îî‚îÄ‚îÄ davon mit 'error'-Feld: {mit_error}\")\n",
    "print(f\"G√ºltige Eintr√§ge (Entities vorhanden): {gueltig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0973154-d5d1-479d-8fd8-642eec02df29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Datei bereingigen & Labels mappen\n",
    "import json\n",
    "\n",
    "# Label-Mapping\n",
    "label_map = {\n",
    "    \"Ort\": \"LOC\",\n",
    "    \"Datum\": \"DATE\",\n",
    "    \"Zeit\": \"TIME\",\n",
    "    \"Kategorie\": \"EVENT\",\n",
    "    \"Thema\": \"TOPIC\"\n",
    "}\n",
    "\n",
    "# JSON laden\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "bereinigt = []\n",
    "for eintrag in data:\n",
    "    entities = eintrag.get(\"entities\")\n",
    "\n",
    "    if not entities or not isinstance(entities, dict):\n",
    "        continue  # √ºberspringen, wenn kaputt oder leer\n",
    "    \n",
    "    # null-Werte rausfiltern und Keys mappen\n",
    "    entities_cleaned = {\n",
    "        label_map.get(k, k): v\n",
    "        for k, v in entities.items()\n",
    "        if v is not None\n",
    "    }\n",
    "\n",
    "    # √ºberspringen, wenn nach dem Filtern nichts √ºbrig ist (optional)\n",
    "    if not entities_cleaned:\n",
    "        continue\n",
    "\n",
    "    eintrag[\"entities\"] = entities_cleaned\n",
    "    bereinigt.append(eintrag)\n",
    "\n",
    "# Speichern\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_2_cleaned.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(bereinigt, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d22ca3-a358-4ead-b324-f47252150a69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Json in Struktur des Goldstandard umwandeln\n",
    "\n",
    "import json\n",
    "\n",
    "# Datei laden\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_2_cleaned.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "# Normalisieren\n",
    "def normalize_to_list(value):\n",
    "    if isinstance(value, list):\n",
    "        return [v.strip() for v in value if isinstance(v, str) and v.strip()]\n",
    "    elif isinstance(value, str) and value.strip():\n",
    "        return [value.strip()]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# In Goldstandard-√§hnliche Struktur bringen\n",
    "converted = []\n",
    "\n",
    "for entry in gemma_data:\n",
    "    file_name = entry.get(\"file_name\")\n",
    "    raw_entities = entry.get(\"entities\", {})\n",
    "    \n",
    "    entities = []\n",
    "    for label, value in raw_entities.items():\n",
    "        values = normalize_to_list(value)\n",
    "        for v in values:\n",
    "            entities.append({\n",
    "                \"label\": label,\n",
    "                \"text\": v\n",
    "            })\n",
    "    \n",
    "    converted.append({\n",
    "        \"file_name\": file_name,\n",
    "        \"entities\": entities\n",
    "    })\n",
    "\n",
    "# Speichern\n",
    "with open(\"../../data/NER/gemma2_prompt2_2_as_goldstructure.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(converted, f, ensure_ascii=False, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99551c8-cc29-43d7-a046-7d468d0c8bbd",
   "metadata": {},
   "source": [
    "### Evaluation - 1. Durchlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff697bd-0eb4-4fde-ad8b-6865177e77e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl Dateien: 183\n",
      "Ung√ºltige Eintr√§ge (keine Entities oder kaputt): 0\n",
      "  ‚îî‚îÄ‚îÄ davon mit 'error'-Feld: 0\n",
      "G√ºltige Eintr√§ge (Entities vorhanden): 183\n"
     ]
    }
   ],
   "source": [
    "# auf \"leere\"/ ung√ºltige Eintr√§ge pr√ºfen\n",
    "import json\n",
    "\n",
    "# JSON laden\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_1_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Z√§hler initialisieren\n",
    "gesamt = len(data)\n",
    "ungueltig = 0\n",
    "mit_error = 0\n",
    "gueltig = 0\n",
    "\n",
    "for eintrag in data:\n",
    "    entities = eintrag.get(\"entities\")\n",
    "    \n",
    "    if not entities or not isinstance(entities, dict):\n",
    "        ungueltig += 1\n",
    "        if \"error\" in eintrag:\n",
    "            mit_error += 1\n",
    "    else:\n",
    "        gueltig += 1\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"Gesamtanzahl Dateien: {gesamt}\")\n",
    "print(f\"Ung√ºltige Eintr√§ge (keine Entities oder kaputt): {ungueltig}\")\n",
    "print(f\"  ‚îî‚îÄ‚îÄ davon mit 'error'-Feld: {mit_error}\")\n",
    "print(f\"G√ºltige Eintr√§ge (Entities vorhanden): {gueltig}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957b30b-9ec0-4bee-86d2-d58110d21f95",
   "metadata": {},
   "source": [
    "---> bei diesem Prompt weniger fehlerhafte Dateien als im notebook 01_gemma2_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df8307b-b863-4403-8b45-6a9e7c1170a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 86355.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Gesamtergebnis (alle Goldstandard-Dateien)\n",
      "Precision: 0.288\n",
      "Recall:    0.185\n",
      "F1-Score:  0.225\n",
      "\n",
      "üìä Metriken pro Kategorie:\n",
      "Label  Precision  Recall  F1-Score  Anzahl in Gold  Anzahl Predicted\n",
      " DATE      0.490   0.328     0.393             290               194\n",
      "EVENT      0.158   0.110     0.129             237               165\n",
      "  LOC      0.266   0.117     0.162             403               177\n",
      " TIME      0.445   0.380     0.410             213               182\n",
      "TOPIC      0.055   0.039     0.046             255               182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# === Dateien laden ===\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_prompt2_1_as_goldstructure.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "# === Zu vergleichende Labels ===\n",
    "label_names = [\"LOC\", \"DATE\", \"TIME\", \"EVENT\", \"TOPIC\"]\n",
    "\n",
    "# === Entit√§ten extrahieren ===\n",
    "def extract_entities(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"text\", \"\").strip()\n",
    "        if label and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "# === Mapping der Vorhersagen f√ºr schnellen Zugriff ===\n",
    "gemma_dict = {entry[\"file_name\"]: entry for entry in gemma_data}\n",
    "\n",
    "# === Vergleich vorbereiten ===\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_true_per_label = defaultdict(list)\n",
    "y_pred_per_label = defaultdict(list)\n",
    "\n",
    "# === Vergleichsloop √ºber alle Goldstandard-Dateien ===\n",
    "for gold_entry in tqdm(gold_data):\n",
    "    file_name = gold_entry[\"file_name\"]\n",
    "    gold_ents = extract_entities(gold_entry)\n",
    "    pred_entry = gemma_dict.get(file_name)\n",
    "    pred_ents = extract_entities(pred_entry) if pred_entry else {}\n",
    "\n",
    "    for label in label_names:\n",
    "        gold_texts = set(t.strip() for t in gold_ents.get(label, []) if isinstance(t, str))\n",
    "        val = pred_ents.get(label)\n",
    "\n",
    "        if isinstance(val, list):\n",
    "            pred_texts = set(t.strip() for t in val if isinstance(t, str))\n",
    "        elif isinstance(val, str):\n",
    "            pred_texts = {val.strip()}\n",
    "        else:\n",
    "            pred_texts = set()\n",
    "\n",
    "        for text in gold_texts:\n",
    "            if text in pred_texts:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(1)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(1)\n",
    "                pred_texts.remove(text)\n",
    "            else:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(0)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(0)\n",
    "\n",
    "        for text in pred_texts:\n",
    "            y_true_all.append(0)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(0)\n",
    "            y_pred_per_label[label].append(1)\n",
    "\n",
    "# === Gesamtmetriken ===\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_all, y_pred_all, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Gesamtergebnis (alle Goldstandard-Dateien)\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "\n",
    "# === Pro-Label-Metriken ===\n",
    "rows = []\n",
    "for label in label_names:\n",
    "    y_true = y_true_per_label[label]\n",
    "    y_pred = y_pred_per_label[label]\n",
    "\n",
    "    if not y_true and not y_pred:\n",
    "        precision = recall = f1 = 0.0\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "    rows.append({\n",
    "        \"Label\": label,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-Score\": round(f1, 3),\n",
    "        \"Anzahl in Gold\": sum(y_true),\n",
    "        \"Anzahl Predicted\": sum(y_pred)\n",
    "    })\n",
    "\n",
    "# Ausgabe\n",
    "df_metrics = pd.DataFrame(rows).sort_values(\"Label\")\n",
    "print(\"\\nüìä Metriken pro Kategorie:\")\n",
    "print(df_metrics.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87bc2c24-02ba-4d78-ac3f-cd6cda87c00d",
   "metadata": {},
   "source": [
    "Werte zuvor:\n",
    "Precision: 0.294\n",
    "Recall:    0.144\n",
    "F1-Score:  0.193\n",
    "\n",
    "üìä Metriken pro Kategorie:\n",
    "Label  Precision  Recall  F1-Score  Anzahl in Gold  Anzahl Predicted\n",
    " DATE      0.433   0.245     0.313             290               164\n",
    "EVENT      0.206   0.135     0.163             237               155\n",
    "  LOC      0.333   0.052     0.090             403                63\n",
    " TIME      0.469   0.315     0.376             213               143\n",
    "TOPIC      0.063   0.039     0.048             255               158"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f721c-39de-4a1e-9516-02f7f57b8013",
   "metadata": {},
   "source": [
    "#### nur Dateien mit erkannten Entit√§ten in die Auswertung mit einbeziehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fe5b71-7398-4390-90f6-a23b1c0f7edd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [00:00<00:00, 80753.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Gesamtergebnis (nur gemeinsame Dateien)\n",
      "Precision: 0.288\n",
      "Recall:    0.204\n",
      "F1-Score:  0.239\n",
      "\n",
      "üìä Metriken pro Kategorie:\n",
      "Label  Precision  Recall  F1-Score  Anzahl in Gold  Anzahl Predicted\n",
      " DATE      0.490   0.365     0.419             260               194\n",
      "EVENT      0.158   0.124     0.139             209               165\n",
      "  LOC      0.266   0.131     0.175             360               177\n",
      " TIME      0.445   0.418     0.431             194               182\n",
      "TOPIC      0.055   0.041     0.047             245               182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# === Dateien laden ===\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_prompt2_1_as_goldstructure.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "# === Zu vergleichende Labels ===\n",
    "label_names = [\"LOC\", \"DATE\", \"TIME\", \"EVENT\", \"TOPIC\"]\n",
    "\n",
    "# === Entit√§ten extrahieren ===\n",
    "def extract_entities(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"text\", \"\").strip()\n",
    "        if label and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "# === Gemeinsame Dateien filtern ===\n",
    "gold_files = {entry[\"file_name\"] for entry in gold_data}\n",
    "gemma_files = {entry[\"file_name\"] for entry in gemma_data}\n",
    "common_files = gold_files & gemma_files\n",
    "\n",
    "filtered_gold = [entry for entry in gold_data if entry[\"file_name\"] in common_files]\n",
    "gemma_dict = {entry[\"file_name\"]: entry for entry in gemma_data if entry[\"file_name\"] in common_files}\n",
    "\n",
    "# === Vergleich vorbereiten ===\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# pro Label getrennte Z√§hlung\n",
    "y_true_per_label = defaultdict(list)\n",
    "y_pred_per_label = defaultdict(list)\n",
    "\n",
    "# === Vergleichsloop ===\n",
    "for gold_entry in tqdm(filtered_gold):\n",
    "    file_name = gold_entry[\"file_name\"]\n",
    "    gold_ents = extract_entities(gold_entry)\n",
    "    pred_entry = gemma_dict.get(file_name)\n",
    "    pred_ents = extract_entities(pred_entry) if pred_entry else {}\n",
    "\n",
    "    for label in label_names:\n",
    "        gold_texts = set(t.strip() for t in gold_ents.get(label, []) if isinstance(t, str))\n",
    "        val = pred_ents.get(label)\n",
    "\n",
    "        if isinstance(val, list):\n",
    "            pred_texts = set(t.strip() for t in val if isinstance(t, str))\n",
    "        elif isinstance(val, str):\n",
    "            pred_texts = {val.strip()}\n",
    "        else:\n",
    "            pred_texts = set()\n",
    "\n",
    "        # True Positives und False Negatives\n",
    "        for text in gold_texts:\n",
    "            if text in pred_texts:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(1)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(1)\n",
    "                pred_texts.remove(text)\n",
    "            else:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(0)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(0)\n",
    "\n",
    "        # Verbleibende Vorhersagen = False Positives\n",
    "        for text in pred_texts:\n",
    "            y_true_all.append(0)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(0)\n",
    "            y_pred_per_label[label].append(1)\n",
    "\n",
    "# === Gesamtmetriken ===\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_all, y_pred_all, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Gesamtergebnis (nur gemeinsame Dateien)\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "\n",
    "# === Metriken pro Label ===\n",
    "rows = []\n",
    "for label in label_names:\n",
    "    y_true = y_true_per_label[label]\n",
    "    y_pred = y_pred_per_label[label]\n",
    "\n",
    "    if not y_true and not y_pred:\n",
    "        precision = recall = f1 = 0.0\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "    rows.append({\n",
    "        \"Label\": label,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-Score\": round(f1, 3),\n",
    "        \"Anzahl in Gold\": sum(y_true),\n",
    "        \"Anzahl Predicted\": sum(y_pred)\n",
    "    })\n",
    "\n",
    "# Ausgabe als Tabelle\n",
    "df_metrics = pd.DataFrame(rows).sort_values(\"Label\")\n",
    "print(\"\\nüìä Metriken pro Kategorie:\")\n",
    "print(df_metrics.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54bfd8-eae7-4eee-b0d1-d625004dd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ergebnis nur wenig besser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f9546-a8a4-4b54-ad7c-e839a6c095e0",
   "metadata": {},
   "source": [
    "--- \n",
    "### Evaluation - 2. Durchlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fb582ae-97df-4b36-8b1c-ff10cb645c9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl Dateien: 173\n",
      "Ung√ºltige Eintr√§ge (keine Entities oder kaputt): 0\n",
      "  ‚îî‚îÄ‚îÄ davon mit 'error'-Feld: 0\n",
      "G√ºltige Eintr√§ge (Entities vorhanden): 173\n"
     ]
    }
   ],
   "source": [
    "# auf \"leere\"/ ung√ºltige Eintr√§ge pr√ºfen\n",
    "import json\n",
    "\n",
    "# JSON laden\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_entity_output_prompt2_2_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Z√§hler initialisieren\n",
    "gesamt = len(data)\n",
    "ungueltig = 0\n",
    "mit_error = 0\n",
    "gueltig = 0\n",
    "\n",
    "for eintrag in data:\n",
    "    entities = eintrag.get(\"entities\")\n",
    "    \n",
    "    if not entities or not isinstance(entities, dict):\n",
    "        ungueltig += 1\n",
    "        if \"error\" in eintrag:\n",
    "            mit_error += 1\n",
    "    else:\n",
    "        gueltig += 1\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"Gesamtanzahl Dateien: {gesamt}\")\n",
    "print(f\"Ung√ºltige Eintr√§ge (keine Entities oder kaputt): {ungueltig}\")\n",
    "print(f\"  ‚îî‚îÄ‚îÄ davon mit 'error'-Feld: {mit_error}\")\n",
    "print(f\"G√ºltige Eintr√§ge (Entities vorhanden): {gueltig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "200a76f1-7059-430b-87eb-12d0e09c1e8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 111788.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Gesamtergebnis 2. Durchlauf (alle Goldstandard-Dateien)\n",
      "Precision: 0.276\n",
      "Recall:    0.175\n",
      "F1-Score:  0.214\n",
      "\n",
      "üìä Metriken pro Kategorie:\n",
      "Label  Precision  Recall  F1-Score  Anzahl in Gold  Anzahl Predicted\n",
      " DATE      0.503   0.324     0.394             290               187\n",
      "EVENT      0.120   0.084     0.099             237               167\n",
      "  LOC      0.239   0.107     0.148             403               180\n",
      " TIME      0.456   0.385     0.417             213               180\n",
      "TOPIC      0.034   0.024     0.028             255               174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# === Dateien laden ===\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2_prompt2_2_as_goldstructure.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "# === Zu vergleichende Labels ===\n",
    "label_names = [\"LOC\", \"DATE\", \"TIME\", \"EVENT\", \"TOPIC\"]\n",
    "\n",
    "# === Entit√§ten extrahieren ===\n",
    "def extract_entities(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"text\", \"\").strip()\n",
    "        if label and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "# === Mapping der Vorhersagen f√ºr schnellen Zugriff ===\n",
    "gemma_dict = {entry[\"file_name\"]: entry for entry in gemma_data}\n",
    "\n",
    "# === Vergleich vorbereiten ===\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_true_per_label = defaultdict(list)\n",
    "y_pred_per_label = defaultdict(list)\n",
    "\n",
    "# === Vergleichsloop √ºber alle Goldstandard-Dateien ===\n",
    "for gold_entry in tqdm(gold_data):\n",
    "    file_name = gold_entry[\"file_name\"]\n",
    "    gold_ents = extract_entities(gold_entry)\n",
    "    pred_entry = gemma_dict.get(file_name)\n",
    "    pred_ents = extract_entities(pred_entry) if pred_entry else {}\n",
    "\n",
    "    for label in label_names:\n",
    "        gold_texts = set(t.strip() for t in gold_ents.get(label, []) if isinstance(t, str))\n",
    "        val = pred_ents.get(label)\n",
    "\n",
    "        if isinstance(val, list):\n",
    "            pred_texts = set(t.strip() for t in val if isinstance(t, str))\n",
    "        elif isinstance(val, str):\n",
    "            pred_texts = {val.strip()}\n",
    "        else:\n",
    "            pred_texts = set()\n",
    "\n",
    "        for text in gold_texts:\n",
    "            if text in pred_texts:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(1)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(1)\n",
    "                pred_texts.remove(text)\n",
    "            else:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(0)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(0)\n",
    "\n",
    "        for text in pred_texts:\n",
    "            y_true_all.append(0)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(0)\n",
    "            y_pred_per_label[label].append(1)\n",
    "\n",
    "# === Gesamtmetriken ===\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_all, y_pred_all, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Gesamtergebnis 2. Durchlauf (alle Goldstandard-Dateien)\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "\n",
    "# === Pro-Label-Metriken ===\n",
    "rows = []\n",
    "for label in label_names:\n",
    "    y_true = y_true_per_label[label]\n",
    "    y_pred = y_pred_per_label[label]\n",
    "\n",
    "    if not y_true and not y_pred:\n",
    "        precision = recall = f1 = 0.0\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "    rows.append({\n",
    "        \"Label\": label,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-Score\": round(f1, 3),\n",
    "        \"Anzahl in Gold\": sum(y_true),\n",
    "        \"Anzahl Predicted\": sum(y_pred)\n",
    "    })\n",
    "\n",
    "# Ausgabe\n",
    "df_metrics = pd.DataFrame(rows).sort_values(\"Label\")\n",
    "print(\"\\nüìä Metriken pro Kategorie:\")\n",
    "print(df_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca15638e-cff0-4ddb-a35f-7ac065ca763b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:00<00:00, 79215.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Gesamtergebnis (nur gemeinsame Dateien)\n",
      "Precision: 0.276\n",
      "Recall:    0.205\n",
      "F1-Score:  0.235\n",
      "\n",
      "üìä Metriken pro Kategorie:\n",
      "Label  Precision  Recall  F1-Score  Anzahl in Gold  Anzahl Predicted\n",
      " DATE      0.503   0.376     0.430             250               187\n",
      "EVENT      0.120   0.099     0.108             202               167\n",
      "  LOC      0.239   0.129     0.167             334               180\n",
      " TIME      0.456   0.446     0.451             184               180\n",
      "TOPIC      0.034   0.027     0.030             225               174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# === Dateien laden ===\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_prompt2_2_as_goldstructure.json\", encoding=\"utf-8\") as f:\n",
    "    gemma_data = json.load(f)\n",
    "\n",
    "# === Zu vergleichende Labels ===\n",
    "label_names = [\"LOC\", \"DATE\", \"TIME\", \"EVENT\", \"TOPIC\"]\n",
    "\n",
    "# === Entit√§ten extrahieren ===\n",
    "def extract_entities(entry):\n",
    "    ent_dict = {}\n",
    "    for ent in entry.get(\"entities\", []):\n",
    "        label = ent.get(\"label\")\n",
    "        text = ent.get(\"text\", \"\").strip()\n",
    "        if label and text:\n",
    "            ent_dict.setdefault(label, []).append(text)\n",
    "    return ent_dict\n",
    "\n",
    "# === Gemeinsame Dateien filtern ===\n",
    "gold_files = {entry[\"file_name\"] for entry in gold_data}\n",
    "gemma_files = {entry[\"file_name\"] for entry in gemma_data}\n",
    "common_files = gold_files & gemma_files\n",
    "\n",
    "filtered_gold = [entry for entry in gold_data if entry[\"file_name\"] in common_files]\n",
    "gemma_dict = {entry[\"file_name\"]: entry for entry in gemma_data if entry[\"file_name\"] in common_files}\n",
    "\n",
    "# === Vergleich vorbereiten ===\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# pro Label getrennte Z√§hlung\n",
    "y_true_per_label = defaultdict(list)\n",
    "y_pred_per_label = defaultdict(list)\n",
    "\n",
    "# === Vergleichsloop ===\n",
    "for gold_entry in tqdm(filtered_gold):\n",
    "    file_name = gold_entry[\"file_name\"]\n",
    "    gold_ents = extract_entities(gold_entry)\n",
    "    pred_entry = gemma_dict.get(file_name)\n",
    "    pred_ents = extract_entities(pred_entry) if pred_entry else {}\n",
    "\n",
    "    for label in label_names:\n",
    "        gold_texts = set(t.strip() for t in gold_ents.get(label, []) if isinstance(t, str))\n",
    "        val = pred_ents.get(label)\n",
    "\n",
    "        if isinstance(val, list):\n",
    "            pred_texts = set(t.strip() for t in val if isinstance(t, str))\n",
    "        elif isinstance(val, str):\n",
    "            pred_texts = {val.strip()}\n",
    "        else:\n",
    "            pred_texts = set()\n",
    "\n",
    "        # True Positives und False Negatives\n",
    "        for text in gold_texts:\n",
    "            if text in pred_texts:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(1)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(1)\n",
    "                pred_texts.remove(text)\n",
    "            else:\n",
    "                y_true_all.append(1)\n",
    "                y_pred_all.append(0)\n",
    "                y_true_per_label[label].append(1)\n",
    "                y_pred_per_label[label].append(0)\n",
    "\n",
    "        # Verbleibende Vorhersagen = False Positives\n",
    "        for text in pred_texts:\n",
    "            y_true_all.append(0)\n",
    "            y_pred_all.append(1)\n",
    "            y_true_per_label[label].append(0)\n",
    "            y_pred_per_label[label].append(1)\n",
    "\n",
    "# === Gesamtmetriken ===\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_all, y_pred_all, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Gesamtergebnis (nur gemeinsame Dateien)\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "\n",
    "# === Metriken pro Label ===\n",
    "rows = []\n",
    "for label in label_names:\n",
    "    y_true = y_true_per_label[label]\n",
    "    y_pred = y_pred_per_label[label]\n",
    "\n",
    "    if not y_true and not y_pred:\n",
    "        precision = recall = f1 = 0.0\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "    rows.append({\n",
    "        \"Label\": label,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-Score\": round(f1, 3),\n",
    "        \"Anzahl in Gold\": sum(y_true),\n",
    "        \"Anzahl Predicted\": sum(y_pred)\n",
    "    })\n",
    "\n",
    "# Ausgabe als Tabelle\n",
    "df_metrics = pd.DataFrame(rows).sort_values(\"Label\")\n",
    "print(\"\\nüìä Metriken pro Kategorie:\")\n",
    "print(df_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d52463-7325-43a3-9265-2a478324dc97",
   "metadata": {},
   "source": [
    "---\n",
    "### Vergleich - √úbereinstimmungen bei fehlerhafter Ausgabe des Jsons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb339903-7349-4a82-b540-38a787825c27",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Eintr√§ge durchlauf1: 183\n",
      "Anzahl der Eintr√§ge durchlauf2: 173\n",
      "Gemeinsame Eintr√§ge (file_name): 159\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_prompt2_1_as_goldstructure.json\", encoding=\"utf-8\") as f:\n",
    "    prompt1 = json.load(f)\n",
    "\n",
    "with open(\"../../data/NER/gemma2/prompt2/gemma2_prompt2_2_as_goldstructure.json\", encoding=\"utf-8\") as f:\n",
    "    prompt2 = json.load(f)\n",
    "\n",
    "# Set der file_names extrahieren\n",
    "file_names1 = {entry['file_name'] for entry in prompt1}\n",
    "file_names2 = {entry['file_name'] for entry in prompt2}\n",
    "\n",
    "\n",
    "gemeinsame = file_names1 & file_names2\n",
    "\n",
    "\n",
    "print(f\"Anzahl der Eintr√§ge durchlauf1: {len(prompt1)}\")\n",
    "print(f\"Anzahl der Eintr√§ge durchlauf2: {len(prompt2)}\")\n",
    "print(f\"Gemeinsame Eintr√§ge (file_name): {len(gemeinsame)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb65d4-7910-4311-80aa-f7e2fa1660a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "---> es wurden bei unterschiedlichen Textfiles keine Entit√§ten extrahiert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
