{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ecca9a-55e8-4827-b24b-f3e27ce14ccf",
   "metadata": {},
   "source": [
    "# Flair Evaluation - 02 -\n",
    "\n",
    "In diesem notebook wird untersucht wie gut flair die gewünschten Entitäten (EVENT, TOPIC, DATE, TIME, LOC) erkennt.\n",
    "\n",
    "Es wird folgendes Model genutzt: **\"ner_german_legal\"**   \n",
    "F1-Score: 96,35 (LER German dataset)\n",
    "\n",
    "Predicts 19 tags:  \n",
    "kein klassisches LOC, aber ST für Stadt und STR für Straße\n",
    "\n",
    " \n",
    "Die Performance von Flair wird auf dem ground truth untersucht. \n",
    "\n",
    "#### note: Es wird bei der Evaluation nur LOC betrachtet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3fe690-c9a4-469d-aeb4-8b2fc49467d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 19:58:27,547 SequenceTagger predicts: Dictionary with 78 tags: <unk>, O, S-AN, B-RS, I-RS, E-RS, B-GS, I-GS, E-GS, B-GRT, I-GRT, E-GRT, S-GRT, B-LIT, I-LIT, E-LIT, B-EUN, I-EUN, E-EUN, B-LD, E-LD, S-RR, B-VT, I-VT, E-VT, B-ORG, I-ORG, E-ORG, B-RR, E-RR, S-GS, B-INN, E-INN, S-INN, S-VT, B-VS, I-VS, E-VS, S-ST, S-LD, S-ORG, B-VO, I-VO, E-VO, S-VS, B-UN, E-UN, S-VO, S-EUN, I-INN\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load(\"flair/ner-german-legal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbe9ba1-76f2-44ff-82fd-1c560ed753a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2120703f-4750-4b5c-a1a0-d685c62cbadd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_flair_entities(text):\n",
    "    sentence = Sentence(text)\n",
    "    tagger.predict(sentence)\n",
    "    predicted = []\n",
    "\n",
    "    for entity in sentence.get_spans(\"ner\"):\n",
    "        predicted.append({\n",
    "            \"text\": entity.text,\n",
    "            \"start\": entity.start_position,\n",
    "            \"end\": entity.end_position,\n",
    "            \"label\": entity.get_label(\"ner\").value\n",
    "        })\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e45184-c4e2-43ce-aacf-872ab009913a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Gesamtbewertung ===\n",
      "Precision: 0.45\n",
      "Recall   : 0.07\n",
      "F1-Score : 0.12\n",
      "\n",
      "=== Bewertung pro Label ===\n",
      "TIME       P: 0.00  R: 0.00  F1: 0.00\n",
      "DATE       P: 0.00  R: 0.00  F1: 0.00\n",
      "LOC        P: 0.46  R: 0.23  F1: 0.30\n",
      "EVENT      P: 0.00  R: 0.00  F1: 0.00\n",
      "TOPIC      P: 0.00  R: 0.00  F1: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Iteration auf dem gesamten Datensatz, Berechnung der Metriken, Speichern der Ergebnisse im Json\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "\n",
    "# Funktion zur erstellung des dictionary\n",
    "def span_to_dict(span, text):\n",
    "    return {\n",
    "        \"text\": text[span[0]:span[1]],\n",
    "        \"start\": span[0],\n",
    "        \"end\": span[1],\n",
    "        \"label\": span[2]\n",
    "    }\n",
    "\n",
    "\n",
    "tp, fp, fn = 0, 0, 0\n",
    "label_stats = defaultdict(lambda: [0, 0, 0])  # TP, FP, FN pro Label\n",
    "relevant_labels = {\"EVENT\", \"TOPIC\", \"TIME\", \"DATE\", \"LOC\"}\n",
    "label_mapping = {\"ST\": \"LOC\", \"STR\": \"LOC\"}\n",
    "all_results = []\n",
    "\n",
    "for eintrag in all_data:\n",
    "    file_name = eintrag.get(\"file_name\", None)\n",
    "    text = eintrag[\"text\"]\n",
    "    gold = eintrag.get(\"entities\", [])\n",
    "    predicted = extract_flair_entities(text)\n",
    "\n",
    "    # Set aus (start, end, label)\n",
    "    gold_spans = {(e[\"start\"], e[\"end\"], e[\"label\"]) for e in gold if e[\"label\"] in relevant_labels}\n",
    "    #pred_spans = {(e[\"start\"], e[\"end\"], e[\"label\"]) for e in predicted if e[\"label\"] in relevant_labels}\n",
    "\n",
    "     # Mapping anwenden\n",
    "    pred_spans = {\n",
    "        (e[\"start\"], e[\"end\"], label_mapping.get(e[\"label\"], e[\"label\"]))\n",
    "        for e in predicted\n",
    "        if label_mapping.get(e[\"label\"], e[\"label\"]) in relevant_labels\n",
    "    }\n",
    "\n",
    "    # Gesamtmetriken\n",
    "    tp += len(gold_spans & pred_spans)\n",
    "    fp += len(pred_spans - gold_spans)\n",
    "    fn += len(gold_spans - pred_spans)\n",
    "\n",
    "    # für Berechnung pro Eintrag\n",
    "    tp_spans = gold_spans & pred_spans\n",
    "    fp_spans = pred_spans - gold_spans\n",
    "    fn_spans = gold_spans - pred_spans\n",
    "    \n",
    "    tp_count = len(tp_spans)\n",
    "    fp_count = len(fp_spans)\n",
    "    fn_count = len(fn_spans)\n",
    "    \n",
    "    # lokale Metriken für dieses Dokument berechnen\n",
    "    precision_local = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0\n",
    "    recall_local = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0\n",
    "    f1_local = 2 * precision_local * recall_local / (precision_local + recall_local) if (precision_local + recall_local) > 0 else 0\n",
    "    \n",
    "\n",
    "    # Pro Label\n",
    "    for label in set([e[\"label\"] for e in gold + predicted]):\n",
    "        if label not in relevant_labels:\n",
    "            continue \n",
    "    \n",
    "        g = {s for s in gold_spans if s[2] == label}\n",
    "        p = {s for s in pred_spans if s[2] == label}\n",
    "        label_stats[label][0] += len(g & p)      # TP\n",
    "        label_stats[label][1] += len(p - g)      # FP\n",
    "        label_stats[label][2] += len(g - p)      # FN\n",
    "\n",
    "    result = {\n",
    "    \"file_name\": file_name,\n",
    "    \"text\": text,\n",
    "    \"precision\": precision_local,\n",
    "    \"recall\": recall_local,\n",
    "    \"f1\": f1_local,\n",
    "    \"true_positives\": [span_to_dict(s, text) for s in tp_spans],\n",
    "    \"false_positives\": [span_to_dict(s, text) for s in fp_spans],\n",
    "    \"false_negatives\": [span_to_dict(s, text) for s in fn_spans],\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    all_results.append(result)\n",
    "\n",
    "# Speichern der results / Ergebnis pro Eintrag\n",
    "with open(\"../../data/NER/flair/results_ner_german_legal.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5. Gesamtergebnisse\n",
    "# -------------------------\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\n=== Gesamtbewertung ===\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall   : {recall:.2f}\")\n",
    "print(f\"F1-Score : {f1:.2f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 6. Bewertung pro Label\n",
    "# -------------------------\n",
    "\n",
    "print(\"\\n=== Bewertung pro Label ===\")\n",
    "for label, (tp_l, fp_l, fn_l) in label_stats.items():\n",
    "    p = tp_l / (tp_l + fp_l) if (tp_l + fp_l) > 0 else 0\n",
    "    r = tp_l / (tp_l + fn_l) if (tp_l + fn_l) > 0 else 0\n",
    "    f = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "    print(f\"{label:<10} P: {p:.2f}  R: {r:.2f}  F1: {f:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a6f8f-4b8e-4366-bec0-922285067471",
   "metadata": {},
   "source": [
    "---\n",
    "### Zählung von True Positives, Overlap Matches, Fuzzy Matches\n",
    "\n",
    "Overlap Machtes: text und label matchen mit Goldstandard  \n",
    "Fuzzy Matches: Text und Label matchen mit Goldstandard und Position ist auf maximal 2 Stellen Abweichnung korrekt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2021529-4a00-48a2-8d22-708484185da6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOC-Ergebnisse ===\n",
      "True Positives (genau): 94\n",
      "Overlap Matches (Text & Label gleich): 98\n",
      "Fuzzy Matches (±2 Zeichen): 99\n",
      "Fuzzy Matches ohne Overlaps: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "with open(\"../../data/NER/flair/results_ner_german_legal.json\", encoding=\"utf-8\") as f:\n",
    "    pred_data = json.load(f)\n",
    "\n",
    "with open(\"../../data/data_annotated.json\", encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "def span_text(span, text):\n",
    "    return text[span[0]:span[1]]\n",
    "\n",
    "def fuzzy_match(gold_span, pred_span, tolerance=2):\n",
    "    return (\n",
    "        gold_span[2] == pred_span[2] and\n",
    "        abs(gold_span[0] - pred_span[0]) <= tolerance and\n",
    "        abs(gold_span[1] - pred_span[1]) <= tolerance\n",
    "    )\n",
    "\n",
    "# Index predicted nach file_name\n",
    "pred_index = {entry[\"file_name\"]: entry for entry in pred_data}\n",
    "\n",
    "\n",
    "tp = 0\n",
    "overlap_matches = 0  # nur text und label sind gleich\n",
    "fuzzy_matches = 0    # text und label sind gleich und position weicht um maximal 2 Zeichen ab\n",
    "\n",
    "for eintrag in gold_data:\n",
    "    file_name = eintrag.get(\"file_name\")\n",
    "    text = eintrag[\"text\"]\n",
    "    gold = [e for e in eintrag.get(\"entities\", []) if e[\"label\"] == \"LOC\"]\n",
    "\n",
    "    pred_entry = pred_index.get(file_name, {})\n",
    "    # Kombiniere TP und FP, FN interessieren hier nicht\n",
    "    predicted = pred_entry.get(\"true_positives\", []) + pred_entry.get(\"false_positives\", [])\n",
    "    predicted = [e for e in predicted if e[\"label\"] == \"LOC\"]\n",
    "\n",
    "    # Erstelle Sets für TP-Zählung\n",
    "    gold_spans = {(e[\"start\"], e[\"end\"], e[\"label\"]) for e in gold}\n",
    "    pred_spans = {(e[\"start\"], e[\"end\"], e[\"label\"]) for e in predicted}\n",
    "\n",
    "    tp += len(gold_spans & pred_spans)\n",
    "\n",
    "    gold_spans_list = list(gold_spans)\n",
    "    pred_spans_list = list(pred_spans)\n",
    "\n",
    "    # Overlap: label und Text gleich\n",
    "    matched_pred_indices = set()\n",
    "    for g in gold_spans:\n",
    "        for i, p in enumerate(pred_spans_list):\n",
    "            if i in matched_pred_indices:\n",
    "                continue\n",
    "            if g[2] == p[2] and span_text(g, text) == span_text(p, text):\n",
    "                overlap_matches += 1\n",
    "                matched_pred_indices.add(i)\n",
    "                break\n",
    "\n",
    "    # Fuzzy Match: ±2 Zeichen Toleranz bei Start/Ende\n",
    "    matched_pred_indices_fuzzy = set()\n",
    "    for g in gold_spans_list:\n",
    "        for i, p in enumerate(pred_spans_list):\n",
    "            if i in matched_pred_indices_fuzzy:\n",
    "                continue\n",
    "            if fuzzy_match(g, p):\n",
    "                fuzzy_matches += 1\n",
    "                matched_pred_indices_fuzzy.add(i)\n",
    "                break\n",
    "\n",
    "print(f\"\\n=== LOC-Ergebnisse ===\")\n",
    "print(f\"True Positives (genau): {tp}\")\n",
    "print(f\"Overlap Matches (Text & Label gleich): {overlap_matches}\")\n",
    "print(f\"Fuzzy Matches (±2 Zeichen): {fuzzy_matches}\")\n",
    "print(f\"Fuzzy Matches ohne Overlaps: {fuzzy_matches - overlap_matches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ef2b8-996c-4e41-ace3-a64da10fa8ec",
   "metadata": {},
   "source": [
    "--> deutlich weniger true posiives als beim Modell ner_german_large  \n",
    "\n",
    "nur 5 Locs haben nicht exakt die gleichen Start- und Endposition wie im Goldstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81137049-fdfe-4251-8911-a6a0e6772a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Flair 3.11)",
   "language": "python",
   "name": "flair311_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
