{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53098c5-bec1-48dd-aeb0-1996747b0325",
   "metadata": {},
   "source": [
    "# EasyOCR - Evaluation - 02 / 03- Preprocessing mit CLAHE\n",
    "\n",
    "In diesem notebook wird ein zweiter Ansatz des Preprocessing ausprobiert mit CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "\n",
    "es werden andere parameter ausprobiert:    \n",
    "alphas = [0.8, 1.5, 2.3, 3.5]         \n",
    "    betas = [-50, 0, 60, 120] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4fe543-6e32-4fc6-8c43-1fb6188ae1e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Prepocessing Funktion\n",
    "import cv2\n",
    "import numpy as np\n",
    "from easyocr import Reader\n",
    "\n",
    "# 1. CLAHE\n",
    "def apply_clahe(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(gray)\n",
    "\n",
    "# 2. Aggressive Varianten\n",
    "def generate_variants(image):\n",
    "    variants = []\n",
    "    alphas = [0.8, 1.5, 2.3, 3.5]       # Kontrast\n",
    "    betas = [-50, 0, 60, 120]           # Helligkeit\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for beta in betas:\n",
    "            adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "            variants.append((adjusted, f\"alpha={alpha}, beta={beta}\"))\n",
    "    return variants\n",
    "\n",
    "# 3. OCR + Confidence-Filter\n",
    "def run_easyocr(image, reader, conf_thresh=0.4):\n",
    "    results = reader.readtext(image)\n",
    "    return [r for r in results if r[2] >= conf_thresh]\n",
    "\n",
    "# 4. Merge-Ergebnisse: nach BoundingBox-Mittelpunkt clustern (einfach, aber effektiv)\n",
    "def merge_results(all_results, iou_thresh=0.3):\n",
    "    merged = []\n",
    "    seen = []\n",
    "\n",
    "    for res in all_results:\n",
    "        (tl, tr, br, bl), text, conf = res\n",
    "        center = ((tl[0] + br[0]) / 2, (tl[1] + br[1]) / 2)\n",
    "\n",
    "        if any(np.linalg.norm(np.array(center) - np.array(seen_c)) < 30 for seen_c in seen):\n",
    "            continue\n",
    "        seen.append(center)\n",
    "        merged.append((text, conf))\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# 4.1 nur zeilen mergen mit hoher confidence\n",
    "def merge_results2(all_results, distance_thresh=30):\n",
    "    merged = []\n",
    "    for res in all_results:\n",
    "        (tl, tr, br, bl), text, conf = res\n",
    "        center = ((tl[0] + br[0]) / 2, (tl[1] + br[1]) / 2)\n",
    "\n",
    "        # PrÃ¼fen, ob ein vorhandenes Ergebnis in der NÃ¤he ist\n",
    "        updated = False\n",
    "        for i, (existing_text, existing_conf, existing_box) in enumerate(merged):\n",
    "            existing_center = ((existing_box[0][0] + existing_box[2][0]) / 2,\n",
    "                               (existing_box[0][1] + existing_box[2][1]) / 2)\n",
    "            dist = np.linalg.norm(np.array(center) - np.array(existing_center))\n",
    "\n",
    "            if dist < distance_thresh:\n",
    "                # Wenn das neue Ergebnis besser ist â†’ ersetzen\n",
    "                if conf > existing_conf:\n",
    "                    merged[i] = (text, conf, (tl, tr, br, bl))\n",
    "                updated = True\n",
    "                break\n",
    "\n",
    "        if not updated:\n",
    "            merged.append((text, conf, (tl, tr, br, bl)))\n",
    "\n",
    "    return merged\n",
    "\n",
    "# 4.2 merge mit treshold um schlechtere Ergebnisse nicht auszugeben\n",
    "def merge_results_tresh(all_results, distance_thresh=30, conf_thresh=0.5):\n",
    "    merged = []\n",
    "    for res in all_results:\n",
    "        (tl, tr, br, bl), text, conf = res\n",
    "\n",
    "        # â¤ Confidence-Filter\n",
    "        if conf < conf_thresh:\n",
    "            continue\n",
    "\n",
    "        center = ((tl[0] + br[0]) / 2, (tl[1] + br[1]) / 2)\n",
    "\n",
    "        updated = False\n",
    "        for i, (existing_text, existing_conf, existing_box) in enumerate(merged):\n",
    "            existing_center = ((existing_box[0][0] + existing_box[2][0]) / 2,\n",
    "                               (existing_box[0][1] + existing_box[2][1]) / 2)\n",
    "            dist = np.linalg.norm(np.array(center) - np.array(existing_center))\n",
    "\n",
    "            if dist < distance_thresh:\n",
    "                if conf > existing_conf:\n",
    "                    merged[i] = (text, conf, (tl, tr, br, bl))\n",
    "                updated = True\n",
    "                break\n",
    "\n",
    "        if not updated:\n",
    "            merged.append((text, conf, (tl, tr, br, bl)))\n",
    "\n",
    "    return merged\n",
    "\n",
    "##########################################################\n",
    "# 5. Main\n",
    "def process_image(image_path):\n",
    "    reader = Reader(['de'])\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    clahe_img = apply_clahe(image)\n",
    "    variants = generate_variants(clahe_img)\n",
    "    \n",
    "    all_results = []\n",
    "    for img, desc in variants:\n",
    "        results = run_easyocr(img, reader)\n",
    "        print(f\"[{desc}] erkannte Texte: {len(results)}\")\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    merged_texts = merge_results(all_results)\n",
    "    print(f\"\\nğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: {len(merged_texts)}\\n\")\n",
    "    for text, conf in merged_texts:\n",
    "        print(f\"{conf:.2f} -> {text}\")\n",
    "\n",
    "# 5.1 mit merge2 kombiniert\n",
    "def process_image2(image_path):\n",
    "    reader = Reader(['de'])\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    clahe_img = apply_clahe(image)\n",
    "    variants = generate_variants(clahe_img)\n",
    "    \n",
    "    all_results = []\n",
    "    for img, desc in variants:\n",
    "        results = run_easyocr(img, reader)\n",
    "        print(f\"[{desc}] erkannte Texte: {len(results)}\")\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    merged_texts = merge_results2(all_results)\n",
    "    print(f\"\\nğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: {len(merged_texts)}\\n\")\n",
    "    for text, conf, _ in merged_texts: # Unterstrich fÃ¼r dritten parameter box, der soll nicht ausgegeben werden, wird ignoriert\n",
    "        print(f\"{conf:.2f} -> {text}\")\n",
    "\n",
    "\n",
    "# 5.2 mit merge mit treshold kombiniert\n",
    "def process_image_tresh(image_path):\n",
    "    reader = Reader(['de', 'en'])\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    clahe_img = apply_clahe(image)\n",
    "    variants = generate_variants(clahe_img)\n",
    "    \n",
    "    all_results = []\n",
    "    for img, desc in variants:\n",
    "        results = run_easyocr(img, reader)\n",
    "        print(f\"[{desc}] erkannte Texte: {len(results)}\")\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    merged_texts = merge_results_tresh(all_results)\n",
    "    print(f\"\\nğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: {len(merged_texts)}\\n\")\n",
    "    for text, conf, _ in merged_texts: # Unterstrich fÃ¼r dritten parameter box, der soll nicht ausgegeben werden, wird ignoriert\n",
    "        print(f\"{conf:.2f} -> {text}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb734b-61ed-400c-8447-f8aa3dd742e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TEST auf Einzelbildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d507df-63b0-43ac-ae8b-6dc6feec250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alpha=0.8, beta=-50] erkannte Texte: 6\n",
      "[alpha=0.8, beta=0] erkannte Texte: 6\n",
      "[alpha=0.8, beta=60] erkannte Texte: 6\n",
      "[alpha=0.8, beta=120] erkannte Texte: 7\n",
      "[alpha=1.5, beta=-50] erkannte Texte: 7\n",
      "[alpha=1.5, beta=0] erkannte Texte: 6\n",
      "[alpha=1.5, beta=60] erkannte Texte: 5\n",
      "[alpha=1.5, beta=120] erkannte Texte: 5\n",
      "[alpha=2.3, beta=-50] erkannte Texte: 6\n",
      "[alpha=2.3, beta=0] erkannte Texte: 5\n",
      "[alpha=2.3, beta=60] erkannte Texte: 3\n",
      "[alpha=2.3, beta=120] erkannte Texte: 3\n",
      "[alpha=3.5, beta=-50] erkannte Texte: 6\n",
      "[alpha=3.5, beta=0] erkannte Texte: 4\n",
      "[alpha=3.5, beta=60] erkannte Texte: 3\n",
      "[alpha=3.5, beta=120] erkannte Texte: 3\n",
      "\n",
      "ğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: 14\n",
      "\n",
      "1.00 -> SPRACHCAFE\n",
      "0.96 -> WEIHNACHTSFEIER\n",
      "0.99 -> DIENSTAG 21.12.\n",
      "0.90 -> OLOF-PALME ZENTRUM\n",
      "0.99 -> 19 UHR\n",
      "0.71 -> WIR FREUEN UnS AUF EUCH!\n",
      "1.00 -> SP\n",
      "0.99 -> CHCAFE\n",
      "1.00 -> WE\n",
      "0.59 -> ~HTSFFTER\n",
      "0.92 -> 4\n",
      "0.65 -> CHCA\n",
      "0.44 -> HCA\n",
      "0.61 -> TSF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_image2(\"../../data/images/insta_images/0001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2f0b5c-0c07-4b32-8093-0933d3c52973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alpha=0.8, beta=-80] erkannte Texte: 6\n",
      "[alpha=0.8, beta=0] erkannte Texte: 6\n",
      "[alpha=0.8, beta=50] erkannte Texte: 6\n",
      "[alpha=0.8, beta=100] erkannte Texte: 8\n",
      "[alpha=1.2, beta=-80] erkannte Texte: 6\n",
      "[alpha=1.2, beta=0] erkannte Texte: 5\n",
      "[alpha=1.2, beta=50] erkannte Texte: 7\n",
      "[alpha=1.2, beta=100] erkannte Texte: 3\n",
      "[alpha=1.8, beta=-80] erkannte Texte: 7\n",
      "[alpha=1.8, beta=0] erkannte Texte: 6\n",
      "[alpha=1.8, beta=50] erkannte Texte: 5\n",
      "[alpha=1.8, beta=100] erkannte Texte: 3\n",
      "[alpha=2.5, beta=-80] erkannte Texte: 7\n",
      "[alpha=2.5, beta=0] erkannte Texte: 4\n",
      "[alpha=2.5, beta=50] erkannte Texte: 4\n",
      "[alpha=2.5, beta=100] erkannte Texte: 2\n",
      "\n",
      "ğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: 12\n",
      "\n",
      "0.94 -> SPRACHCAFE\n",
      "0.75 -> WEIHNACHTSFEIER\n",
      "0.98 -> DIENSTAG 21.12\n",
      "0.65 -> OLOF-PALME ZENTRUM\n",
      "1.00 -> 19 UHR\n",
      "0.65 -> WIR FREUEN UNS AUF EUCH!\n",
      "1.00 -> SP\n",
      "0.99 -> CHCAFE\n",
      "0.79 -> WEIF\n",
      "0.76 -> GHTSFEIER\n",
      "0.67 -> CHCA\n",
      "0.50 -> HTSFFFR\n"
     ]
    }
   ],
   "source": [
    "# Beispiel-Aufruf\n",
    "process_image(\"../../data/images/insta_images/0001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49574c02-7210-47d4-bf62-0e36aba6645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alpha=0.8, beta=-50] erkannte Texte: 8\n",
      "[alpha=0.8, beta=0] erkannte Texte: 9\n",
      "[alpha=0.8, beta=60] erkannte Texte: 8\n",
      "[alpha=0.8, beta=120] erkannte Texte: 8\n",
      "[alpha=1.5, beta=-50] erkannte Texte: 11\n",
      "[alpha=1.5, beta=0] erkannte Texte: 7\n",
      "[alpha=1.5, beta=60] erkannte Texte: 7\n",
      "[alpha=1.5, beta=120] erkannte Texte: 6\n",
      "[alpha=2.3, beta=-50] erkannte Texte: 9\n",
      "[alpha=2.3, beta=0] erkannte Texte: 6\n",
      "[alpha=2.3, beta=60] erkannte Texte: 9\n",
      "[alpha=2.3, beta=120] erkannte Texte: 2\n",
      "[alpha=3.5, beta=-50] erkannte Texte: 8\n",
      "[alpha=3.5, beta=0] erkannte Texte: 7\n",
      "[alpha=3.5, beta=60] erkannte Texte: 2\n",
      "[alpha=3.5, beta=120] erkannte Texte: 6\n",
      "\n",
      "ğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: 20\n",
      "\n",
      "1.00 -> 8â‚¬\n",
      "1.00 -> Abend\n",
      "0.97 -> Roter\n",
      "1.00 -> Salon\n",
      "0.66 -> Eintritt:\n",
      "0.76 -> Wannz\n",
      "0.73 -> CoLole\n",
      "0.91 -> arbeitskaempfe@volksbuehne-berlin-de\n",
      "0.94 -> PUN\n",
      "0.49 -> 94\n",
      "0.99 -> 4\n",
      "0.65 -> Wer:\n",
      "0.79 -> ZLu#2\n",
      "0.95 -> 4\n",
      "0.98 -> der\n",
      "0.86 -> in\n",
      "0.58 -> MOLKSBUANE\n",
      "0.44 -> 492\n",
      "0.49 -> 44\n",
      "0.45 -> Derlin de\n"
     ]
    }
   ],
   "source": [
    "process_image2(\"../../data/images/insta_images/0239.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d06b01-b658-4412-9f1d-7d89e62ba4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alpha=0.8, beta=-50] erkannte Texte: 8\n",
      "[alpha=0.8, beta=0] erkannte Texte: 9\n",
      "[alpha=0.8, beta=60] erkannte Texte: 8\n",
      "[alpha=0.8, beta=120] erkannte Texte: 8\n",
      "[alpha=1.5, beta=-50] erkannte Texte: 11\n",
      "[alpha=1.5, beta=0] erkannte Texte: 7\n",
      "[alpha=1.5, beta=60] erkannte Texte: 7\n",
      "[alpha=1.5, beta=120] erkannte Texte: 6\n",
      "[alpha=2.3, beta=-50] erkannte Texte: 9\n",
      "[alpha=2.3, beta=0] erkannte Texte: 6\n",
      "[alpha=2.3, beta=60] erkannte Texte: 9\n",
      "[alpha=2.3, beta=120] erkannte Texte: 2\n",
      "[alpha=3.5, beta=-50] erkannte Texte: 8\n",
      "[alpha=3.5, beta=0] erkannte Texte: 7\n",
      "[alpha=3.5, beta=60] erkannte Texte: 2\n",
      "[alpha=3.5, beta=120] erkannte Texte: 6\n",
      "\n",
      "ğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: 20\n",
      "\n",
      "1.00 -> 8â‚¬\n",
      "1.00 -> Abend\n",
      "0.93 -> Roter\n",
      "1.00 -> Salon\n",
      "0.66 -> Eintritt:\n",
      "0.64 -> Wannz\n",
      "0.73 -> CoLole\n",
      "0.72 -> arbeitskaempfe@volksbuehne-berlin-de\n",
      "0.66 -> PUNA\n",
      "0.49 -> 94\n",
      "0.92 -> 4\n",
      "0.56 -> Wer:\n",
      "0.79 -> ZLu#2\n",
      "0.95 -> 4\n",
      "0.47 -> der\n",
      "0.86 -> in\n",
      "0.51 -> VOLKSBUANE\n",
      "0.44 -> 492\n",
      "0.49 -> 44\n",
      "0.45 -> Derlin de\n"
     ]
    }
   ],
   "source": [
    "# Beispiel-Aufruf\n",
    "process_image(\"../../data/images/insta_images/0239.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54f05866-77ed-4065-aecc-f4d90566ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alpha=0.8, beta=-80] erkannte Texte: 10\n",
      "[alpha=0.8, beta=0] erkannte Texte: 11\n",
      "[alpha=0.8, beta=50] erkannte Texte: 11\n",
      "[alpha=0.8, beta=100] erkannte Texte: 3\n",
      "[alpha=1.2, beta=-80] erkannte Texte: 12\n",
      "[alpha=1.2, beta=0] erkannte Texte: 4\n",
      "[alpha=1.2, beta=50] erkannte Texte: 3\n",
      "[alpha=1.2, beta=100] erkannte Texte: 0\n",
      "[alpha=1.8, beta=-80] erkannte Texte: 3\n",
      "[alpha=1.8, beta=0] erkannte Texte: 1\n",
      "[alpha=1.8, beta=50] erkannte Texte: 0\n",
      "[alpha=1.8, beta=100] erkannte Texte: 0\n",
      "[alpha=2.5, beta=-80] erkannte Texte: 0\n",
      "[alpha=2.5, beta=0] erkannte Texte: 0\n",
      "[alpha=2.5, beta=50] erkannte Texte: 0\n",
      "[alpha=2.5, beta=100] erkannte Texte: 0\n",
      "\n",
      "ğŸ¯ Gesamterkannte (gefilterte + gemergte) Texte: 20\n",
      "\n",
      "0.99 -> IS PALESTINE\n",
      "0.99 -> AFEMINIST\n",
      "0.97 -> ISSUE?I\n",
      "0.93 -> ZURVERSCHRANKUNG\n",
      "1.00 -> VON\n",
      "1.00 -> (QUEER-)FEMINISMUS\n",
      "0.87 -> UND ANTISEMITISMUS\n",
      "0.99 -> & Diskussion mit\n",
      "0.95 -> Do 19.12.\n",
      "0.83 -> 19-00 Uhr\n",
      "0.83 -> Vortrag & Diskussion mit\n",
      "0.98 -> Cordula Trunk\n",
      "0.60 -> 4\n",
      "1.00 -> FEMINIST\n",
      "0.53 -> ;\n",
      "1.00 -> Trunk\n",
      "0.99 -> 8\n",
      "0.67 -> |\n",
      "0.69 -> 2\n",
      "0.51 -> 5\n"
     ]
    }
   ],
   "source": [
    "process_image_tresh(\"../../data/images/insta_images/0180.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5371518-2cfd-4408-b613-b49742d091b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IS PALESTINE', '4', 'FEMINIST', 'ISSUE?!', 'ZUR VERSCHRÃ„NKUNG', 'VON', '(QUEER-)FEMINISMUS', 'UND ANTISEMITISMUS', 'coaqfPiak', '& Diskussion mit', ';', 'Trunk', '|', 'Do 19.12.', ':', '19:00 Uhr', 'Ã„']\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from easyocr import Reader\n",
    "reader = easyocr.Reader(['de'])  \n",
    "result = reader.readtext('../../data/images/insta_images/0180.jpg', detail=0) # bei 0 wird boundingbox wird nicht angezeigt\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4df14c-a522-46ba-9f76-7ab78de6bd95",
   "metadata": {},
   "source": [
    "---\n",
    "### Anwendung auf gesamtem Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d04f20-de51-45d5-a2c9-e363b7d60fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from easyocr import Reader\n",
    "import sys # ermÃ¶glicht Zugriff auf Ã¼bergeordnetes Verzeichnis\n",
    "sys.path.append(os.path.abspath(\"../../utils\"))\n",
    "from funktionen import cer_for_matching, match_gt_to_ocr, calculate_wer,calculate_cer, CER_THRESHOLD\n",
    "\n",
    "\n",
    "\n",
    "# 1. CLAHE\n",
    "def apply_clahe(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(gray)\n",
    "\n",
    "# 2. Varianten\n",
    "def generate_variants(image):\n",
    "    variants = []\n",
    "    alphas = [0.8, 1.5, 2.3, 3.5]       # Kontrast\n",
    "    betas = [-50, 0, 60, 120] \n",
    "    for alpha in alphas:\n",
    "        for beta in betas:\n",
    "            adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "            variants.append((adjusted, f\"alpha={alpha}, beta={beta}\"))\n",
    "    return variants\n",
    "\n",
    "# 3. OCR mit Filter\n",
    "def run_easyocr(image, reader, conf_thresh=0.4):\n",
    "    results = reader.readtext(image)\n",
    "    return [r for r in results if r[2] >= conf_thresh]\n",
    "\n",
    "# 4. Merge nach Bounding-Box-Mittelpunkt\n",
    "def merge_results(all_results, distance_thresh=30):\n",
    "    merged = []\n",
    "    for res in all_results:\n",
    "        (tl, tr, br, bl), text, conf = res\n",
    "        center = ((tl[0] + br[0]) / 2, (tl[1] + br[1]) / 2)\n",
    "\n",
    "        # PrÃ¼fen, ob ein vorhandenes Ergebnis in der NÃ¤he ist\n",
    "        updated = False\n",
    "        for i, (existing_text, existing_conf, existing_box) in enumerate(merged):\n",
    "            existing_center = ((existing_box[0][0] + existing_box[2][0]) / 2,\n",
    "                               (existing_box[0][1] + existing_box[2][1]) / 2)\n",
    "            dist = np.linalg.norm(np.array(center) - np.array(existing_center))\n",
    "\n",
    "            if dist < distance_thresh:\n",
    "                # Wenn das neue Ergebnis besser ist â†’ ersetzen\n",
    "                if conf > existing_conf:\n",
    "                    merged[i] = (text, conf, (tl, tr, br, bl))\n",
    "                updated = True\n",
    "                break\n",
    "\n",
    "        if not updated:\n",
    "            merged.append((text, conf, (tl, tr, br, bl)))\n",
    "\n",
    "    return merged\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_ocr_with_metrics(gt_lines, ocr_lines):\n",
    "    matches = match_gt_to_ocr(gt_lines, ocr_lines)\n",
    "    total_gt = len(gt_lines)\n",
    "    total_ocr = len(ocr_lines)\n",
    "    total_matches = sum(1 for (_, ocr_idx) in matches if ocr_idx is not None)\n",
    "\n",
    "    cer_list = []\n",
    "    wer_list = []\n",
    "\n",
    "    for gt_idx, ocr_idx in matches:\n",
    "        gt = gt_lines[gt_idx]\n",
    "        pred = ocr_lines[ocr_idx] if ocr_idx is not None else \"\"\n",
    "        cer_list.append(calculate_cer(gt, pred))\n",
    "        wer_list.append(calculate_wer(gt, pred))\n",
    "\n",
    "    mean_cer = sum(cer_list) / total_gt if total_gt else None\n",
    "    mean_wer = sum(wer_list) / total_gt if total_gt else None\n",
    "\n",
    "    return {\n",
    "        \"gt_lines\": total_gt,\n",
    "        \"ocr_lines\": total_ocr,\n",
    "        \"matched_lines\": total_matches,\n",
    "        \"mean_cer\": mean_cer,\n",
    "        \"mean_wer\": mean_wer\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# 5. Hauptfunktion fÃ¼r ein Bild\n",
    "def process_image(image_path, reader):\n",
    "    image = cv2.imread(image_path)\n",
    "    clahe_img = apply_clahe(image)\n",
    "    variants = generate_variants(clahe_img)\n",
    "\n",
    "    all_results = []\n",
    "    for img, desc in variants:\n",
    "        results = run_easyocr(img, reader)\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    merged = merge_results(all_results)\n",
    "    return [text for text, conf, box in merged]  # â† Nur Texte extrahieren\n",
    "\n",
    "\n",
    "\n",
    "# 6. Batch-Verarbeitung + CSV Export\n",
    "def process_folder_with_eval(image_folder, gt_dict, output_csv):\n",
    "    reader = Reader(['de')\n",
    "    results = []\n",
    "\n",
    "    for fname in os.listdir(image_folder):\n",
    "        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(image_folder, fname)\n",
    "        print(f\"ğŸ” Verarbeite: {fname}\")\n",
    "        try:\n",
    "            ocr_lines = process_image(img_path, reader)  # EasyOCR-Ausgabe\n",
    "            gt_lines = gt_dict.get(fname, [])\n",
    "\n",
    "            eval_result = evaluate_ocr_with_metrics(gt_lines, ocr_lines)\n",
    "            eval_result.update({\n",
    "                \"file_name\": fname,\n",
    "                \"ocr_easyocr_clahe\": ocr_lines\n",
    "            })\n",
    "\n",
    "            results.append(eval_result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Fehler bei {fname}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nâœ… Export abgeschlossen: {output_csv} (Dateien: {len(df)})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff526b44-cfee-41a6-be85-6b08d609a6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Verarbeite: 0071.jpg\n",
      "ğŸ” Verarbeite: 0059.jpg\n",
      "ğŸ” Verarbeite: 0111.jpg\n",
      "ğŸ” Verarbeite: 0139.jpg\n",
      "ğŸ” Verarbeite: 0110.jpg\n",
      "ğŸ” Verarbeite: 0104.jpg\n",
      "ğŸ” Verarbeite: 0039.jpeg\n",
      "ğŸ” Verarbeite: 0064.jpg\n",
      "ğŸ” Verarbeite: 0066.jpg\n",
      "ğŸ” Verarbeite: 0072.jpg\n",
      "ğŸ” Verarbeite: 0099.jpg\n",
      "ğŸ” Verarbeite: 0112.jpg\n",
      "ğŸ” Verarbeite: 0106.jpg\n",
      "ğŸ” Verarbeite: 0113.jpg\n",
      "ğŸ” Verarbeite: 0131.jpeg\n",
      "ğŸ” Verarbeite: 0127.jpeg\n",
      "ğŸ” Verarbeite: 0098.jpg\n",
      "ğŸ” Verarbeite: 0170.jpeg\n",
      "ğŸ” Verarbeite: 0063.jpg\n",
      "ğŸ” Verarbeite: 0117.jpg\n",
      "ğŸ” Verarbeite: 0103.jpg\n",
      "ğŸ” Verarbeite: 0116.jpg\n",
      "ğŸ” Verarbeite: 0018.jpeg\n",
      "ğŸ” Verarbeite: 0062.jpg\n",
      "ğŸ” Verarbeite: 0074.jpg\n",
      "ğŸ” Verarbeite: 0060.jpg\n",
      "ğŸ” Verarbeite: 0128.jpg\n",
      "ğŸ” Verarbeite: 0100.jpg\n",
      "ğŸ” Verarbeite: 0114.jpg\n",
      "ğŸ” Verarbeite: 0115.jpg\n",
      "ğŸ” Verarbeite: 0101.jpg\n",
      "ğŸ” Verarbeite: 0129.jpg\n",
      "ğŸ” Verarbeite: 0147.jpeg\n",
      "ğŸ” Verarbeite: 0061.jpg\n",
      "ğŸ” Verarbeite: 0075.jpg\n",
      "ğŸ” Verarbeite: 0049.jpg\n",
      "ğŸ” Verarbeite: 0012.jpg\n",
      "ğŸ” Verarbeite: 0006.jpg\n",
      "ğŸ” Verarbeite: 0210.jpg\n",
      "ğŸ” Verarbeite: 0204.jpg\n",
      "ğŸ” Verarbeite: 0238.jpg\n",
      "ğŸ” Verarbeite: 0166.jpg\n",
      "ğŸ” Verarbeite: 0172.jpg\n",
      "ğŸ” Verarbeite: 0199.jpg\n",
      "ğŸ” Verarbeite: 0198.jpg\n",
      "ğŸ” Verarbeite: 0173.jpg\n",
      "ğŸ” Verarbeite: 0167.jpg\n",
      "ğŸ” Verarbeite: 0239.jpg\n",
      "ğŸ” Verarbeite: 0205.jpg\n",
      "ğŸ” Verarbeite: 0211.jpg\n",
      "ğŸ” Verarbeite: 0007.jpg\n",
      "ğŸ” Verarbeite: 0013.jpg\n",
      "ğŸ” Verarbeite: 0011.jpg\n",
      "ğŸ” Verarbeite: 0207.jpg\n",
      "ğŸ” Verarbeite: 0156.jpeg\n",
      "ğŸ” Verarbeite: 0213.jpg\n",
      "ğŸ” Verarbeite: 0171.jpg\n",
      "ğŸ” Verarbeite: 0165.jpg\n",
      "ğŸ” Verarbeite: 0052.jpeg\n",
      "ğŸ” Verarbeite: 0158.jpg\n",
      "ğŸ” Verarbeite: 0164.jpg\n",
      "ğŸ” Verarbeite: 0212.jpg\n",
      "ğŸ” Verarbeite: 0206.jpg\n",
      "ğŸ” Verarbeite: 0010.jpg\n",
      "ğŸ” Verarbeite: 0004.jpg\n",
      "ğŸ” Verarbeite: 0028.jpg\n",
      "ğŸ” Verarbeite: 0014.jpg\n",
      "ğŸ” Verarbeite: 0202.jpg\n",
      "ğŸ” Verarbeite: 0216.jpg\n",
      "ğŸ” Verarbeite: 0090.jpeg\n",
      "ğŸ” Verarbeite: 0148.jpg\n",
      "ğŸ” Verarbeite: 0160.jpg\n",
      "ğŸ” Verarbeite: 0161.jpg\n",
      "ğŸ” Verarbeite: 0149.jpg\n",
      "ğŸ” Verarbeite: 0217.jpg\n",
      "ğŸ” Verarbeite: 0203.jpg\n",
      "ğŸ” Verarbeite: 0015.jpg\n",
      "ğŸ” Verarbeite: 0001.jpg\n",
      "ğŸ” Verarbeite: 0029.jpg\n",
      "ğŸ” Verarbeite: 0045.jpeg\n",
      "ğŸ” Verarbeite: 0017.jpg\n",
      "ğŸ” Verarbeite: 0003.jpg\n",
      "ğŸ” Verarbeite: 0229.jpg\n",
      "ğŸ” Verarbeite: 0215.jpg\n",
      "ğŸ” Verarbeite: 0201.jpg\n",
      "ğŸ” Verarbeite: 0073.jpeg\n",
      "ğŸ” Verarbeite: 0163.jpg\n",
      "ğŸ” Verarbeite: 0177.jpg\n",
      "ğŸ” Verarbeite: 0176.jpg\n",
      "ğŸ” Verarbeite: 0200.jpg\n",
      "ğŸ” Verarbeite: 0214.jpg\n",
      "ğŸ” Verarbeite: 0228.jpg\n",
      "ğŸ” Verarbeite: 0002.jpg\n",
      "ğŸ” Verarbeite: 0016.jpg\n",
      "ğŸ” Verarbeite: 0027.jpg\n",
      "ğŸ” Verarbeite: 0231.jpg\n",
      "ğŸ” Verarbeite: 0089.jpeg\n",
      "ğŸ” Verarbeite: 0225.jpg\n",
      "ğŸ” Verarbeite: 0219.jpg\n",
      "ğŸ” Verarbeite: 0162.jpeg\n",
      "ğŸ” Verarbeite: 0153.jpg\n",
      "ğŸ” Verarbeite: 0190.jpg\n",
      "ğŸ” Verarbeite: 0191.jpg\n",
      "ğŸ” Verarbeite: 0119.jpeg\n",
      "ğŸ” Verarbeite: 0185.jpg\n",
      "ğŸ” Verarbeite: 0152.jpg\n",
      "ğŸ” Verarbeite: 0146.jpg\n",
      "ğŸ” Verarbeite: 0218.jpg\n",
      "ğŸ” Verarbeite: 0224.jpg\n",
      "ğŸ” Verarbeite: 0230.jpg\n",
      "ğŸ” Verarbeite: 0026.jpg\n",
      "ğŸ” Verarbeite: 0032.jpg\n",
      "ğŸ” Verarbeite: 0024.jpg\n",
      "ğŸ” Verarbeite: 0030.jpg\n",
      "ğŸ” Verarbeite: 0226.jpg\n",
      "ğŸ” Verarbeite: 0232.jpg\n",
      "ğŸ” Verarbeite: 0178.jpg\n",
      "ğŸ” Verarbeite: 0193.jpg\n",
      "ğŸ” Verarbeite: 0187.jpg\n",
      "ğŸ” Verarbeite: 0186.jpg\n",
      "ğŸ” Verarbeite: 0179.jpg\n",
      "ğŸ” Verarbeite: 0145.jpg\n",
      "ğŸ” Verarbeite: 0151.jpg\n",
      "ğŸ” Verarbeite: 0142.jpeg\n",
      "ğŸ” Verarbeite: 0233.jpg\n",
      "ğŸ” Verarbeite: 0154.jpeg\n",
      "ğŸ” Verarbeite: 0227.jpg\n",
      "ğŸ” Verarbeite: 0046.jpeg\n",
      "ğŸ” Verarbeite: 0019.jpg\n",
      "ğŸ” Verarbeite: 0031.jpg\n",
      "ğŸ” Verarbeite: 0025.jpg\n",
      "ğŸ” Verarbeite: 0009.jpg\n",
      "ğŸ” Verarbeite: 0035.jpg\n",
      "ğŸ” Verarbeite: 0223.jpg\n",
      "ğŸ” Verarbeite: 0237.jpg\n",
      "ğŸ” Verarbeite: 0155.jpg\n",
      "ğŸ” Verarbeite: 0196.jpg\n",
      "ğŸ” Verarbeite: 0182.jpg\n",
      "ğŸ” Verarbeite: 0183.jpg\n",
      "ğŸ” Verarbeite: 0197.jpg\n",
      "ğŸ” Verarbeite: 0140.jpg\n",
      "ğŸ” Verarbeite: 0236.jpg\n",
      "ğŸ” Verarbeite: 0222.jpg\n",
      "ğŸ” Verarbeite: 0020.jpg\n",
      "ğŸ” Verarbeite: 0036.jpg\n",
      "ğŸ” Verarbeite: 0022.jpg\n",
      "ğŸ” Verarbeite: 0208.jpg\n",
      "ğŸ” Verarbeite: 0234.jpg\n",
      "ğŸ” Verarbeite: 0220.jpg\n",
      "ğŸ” Verarbeite: 0181.jpg\n",
      "ğŸ” Verarbeite: 0118.jpeg\n",
      "ğŸ” Verarbeite: 0195.jpg\n",
      "ğŸ” Verarbeite: 0194.jpg\n",
      "ğŸ” Verarbeite: 0180.jpg\n",
      "ğŸ” Verarbeite: 0157.jpg\n",
      "ğŸ” Verarbeite: 0143.jpg\n",
      "ğŸ” Verarbeite: 0221.jpg\n",
      "ğŸ” Verarbeite: 0235.jpg\n",
      "ğŸ” Verarbeite: 0067.jpeg\n",
      "ğŸ” Verarbeite: 0209.jpg\n",
      "ğŸ” Verarbeite: 0023.jpg\n",
      "ğŸ” Verarbeite: 0050.jpg\n",
      "ğŸ” Verarbeite: 0044.jpg\n",
      "ğŸ” Verarbeite: 0093.jpg\n",
      "ğŸ” Verarbeite: 0078.png\n",
      "ğŸ” Verarbeite: 0124.jpg\n",
      "ğŸ” Verarbeite: 0130.jpg\n",
      "ğŸ” Verarbeite: 0086.jpg\n",
      "ğŸ” Verarbeite: 0040.jpeg\n",
      "ğŸ” Verarbeite: 0051.jpg\n",
      "ğŸ” Verarbeite: 0047.jpg\n",
      "ğŸ” Verarbeite: 0037.jpeg\n",
      "ğŸ” Verarbeite: 0133.jpg\n",
      "ğŸ” Verarbeite: 0132.jpg\n",
      "ğŸ” Verarbeite: 0091.jpg\n",
      "ğŸ” Verarbeite: 0081.jpg\n",
      "ğŸ” Verarbeite: 0095.jpg\n",
      "ğŸ” Verarbeite: 0240.jpg\n",
      "ğŸ” Verarbeite: 0136.jpg\n",
      "ğŸ” Verarbeite: 0122.jpg\n",
      "ğŸ” Verarbeite: 0123.jpg\n",
      "ğŸ” Verarbeite: 0137.jpg\n",
      "ğŸ” Verarbeite: 0241.jpg\n",
      "ğŸ” Verarbeite: 0094.jpg\n",
      "ğŸ” Verarbeite: 0080.jpg\n",
      "ğŸ” Verarbeite: 0057.jpg\n",
      "ğŸ” Verarbeite: 0043.jpg\n",
      "ğŸ” Verarbeite: 0055.jpg\n",
      "ğŸ” Verarbeite: 0041.jpg\n",
      "ğŸ” Verarbeite: 0096.jpg\n",
      "ğŸ” Verarbeite: 0082.jpg\n",
      "ğŸ” Verarbeite: 0121.jpg\n",
      "ğŸ” Verarbeite: 0135.jpg\n",
      "ğŸ” Verarbeite: 0169.jpeg\n",
      "ğŸ” Verarbeite: 0134.jpg\n",
      "ğŸ” Verarbeite: 0120.jpg\n",
      "ğŸ” Verarbeite: 0108.jpg\n",
      "ğŸ” Verarbeite: 0242.jpg\n",
      "ğŸ” Verarbeite: 0097.jpg\n",
      "ğŸ” Verarbeite: 0054.jpg\n",
      "\n",
      "âœ… Export abgeschlossen: ../../data/OCR/ocr_evaluation_clahe3.csv (Dateien: 200)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "JSON_PATH = \"../../data/data_annotated.json\"\n",
    "\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "gt_dict = {e[\"file_name\"]: e.get(\"lines\", []) for e in all_data if \"file_name\" in e}\n",
    "\n",
    "process_folder_with_eval(\"../../data/images/insta_images\", gt_dict, \"../../data/OCR/easyocr/ocr_evaluation_clahe3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518c4966-1d34-4c9e-b236-21062869f6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt_lines</th>\n",
       "      <th>ocr_lines</th>\n",
       "      <th>matched_lines</th>\n",
       "      <th>mean_cer</th>\n",
       "      <th>mean_wer</th>\n",
       "      <th>file_name</th>\n",
       "      <th>ocr_easyocr_clahe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660652</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0071.jpg</td>\n",
       "      <td>['Freedom Porade |?11', '0', 'Brandeaburger To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.763975</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0059.jpg</td>\n",
       "      <td>['8.', '19 UHR, KUFA MOABIT_', 'Gcfordert durc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0.241408</td>\n",
       "      <td>0.297436</td>\n",
       "      <td>0111.jpg</td>\n",
       "      <td>['50 JAHRE', 'RI', 'RUMBLE IN THE JUNGLE', 'Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.252193</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0139.jpg</td>\n",
       "      <td>['MEHR POLIZEI?', 'NICHTS ZU FEIERN', 'WIR BLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.329697</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0110.jpg</td>\n",
       "      <td>['CLUBS', 'STADT', 'KLIMAKRISE', 'MARKGRAFENDA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gt_lines  ocr_lines  matched_lines  mean_cer  mean_wer file_name  \\\n",
       "0         7         16              3  0.660652  0.857143  0071.jpg   \n",
       "1         7         13              2  0.763975  0.750000  0059.jpg   \n",
       "2        13         35             11  0.241408  0.297436  0111.jpg   \n",
       "3         8         13              6  0.252193  0.265625  0139.jpg   \n",
       "4         5          8              4  0.329697  0.900000  0110.jpg   \n",
       "\n",
       "                                   ocr_easyocr_clahe  \n",
       "0  ['Freedom Porade |?11', '0', 'Brandeaburger To...  \n",
       "1  ['8.', '19 UHR, KUFA MOABIT_', 'Gcfordert durc...  \n",
       "2  ['50 JAHRE', 'RI', 'RUMBLE IN THE JUNGLE', 'Po...  \n",
       "3  ['MEHR POLIZEI?', 'NICHTS ZU FEIERN', 'WIR BLE...  \n",
       "4  ['CLUBS', 'STADT', 'KLIMAKRISE', 'MARKGRAFENDA...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/OCR/easyocr/ocr_evaluation_clahe3.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cef97c-da93-4997-828e-fa2038018397",
   "metadata": {},
   "source": [
    "### Evaluation - Berechnung CER und WER - zeilenbasiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0010ebd2-9768-4424-8fa1-77f2ae14273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"recognition_rate\"] = df[\"matched_lines\"] / df[\"gt_lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d945d9f7-7305-4884-b1ea-2d31130debcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittswerte ganzer Datensatz:\n",
      "Erkennungsrate: 0.718\n",
      "CER: 0.336\n",
      "WER: 0.507\n"
     ]
    }
   ],
   "source": [
    "# Durchschnitt berechnen\n",
    "mean_cer = df[\"mean_cer\"].mean()\n",
    "mean_wer = df[\"mean_wer\"].mean()\n",
    "mean_ER = df[\"recognition_rate\"].mean()\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"Durchschnittswerte ganzer Datensatz:\")\n",
    "print(f\"Erkennungsrate: {mean_ER:.3f}\")\n",
    "print(f\"CER: {mean_cer:.3f}\")\n",
    "print(f\"WER: {mean_wer:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd02bf-d01e-40a2-93d6-e997374a3426",
   "metadata": {},
   "source": [
    "Werte 1. Versuch mit Clahe:    \n",
    "Erkennungsrate: 0.730  \n",
    "CER: 0.326   \n",
    "WER: 0.496  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b1ba7-71e0-4bfc-8154-b8de4c36ab03",
   "metadata": {},
   "source": [
    "##### ---> Werte sind schlechter als beim ersten Versuch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f64f81-abd7-49f1-8e15-a68a9e8a5d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5d9b9-b043-42cb-8ba6-17ebac003ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
